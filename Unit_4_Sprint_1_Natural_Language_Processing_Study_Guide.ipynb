{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "enodNfbMIxzN"
   },
   "source": [
    "This study guide should reinforce and provide practice for all of the concepts you have seen in the past week. There are a mix of written questions and coding exercises, both are equally important to prepare you for the sprint challenge as well as to be able to speak on these topics comfortably in interviews and on the job.\n",
    "\n",
    "If you get stuck or are unsure of something remember the 20 minute rule. If that doesn't help, then research a solution with google and stackoverflow. Only once you have exausted these methods should you turn to your Team Lead - they won't be there on your SC or during an interview. That being said, don't hesitate to ask for help if you truly are stuck.\n",
    "\n",
    "Have fun studying!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mjVNoILlDD83"
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 242
    },
    "colab_type": "code",
    "id": "LMQBp_ddC9CX",
    "outputId": "688a6986-7a3c-4a90-9a7d-c93f36cf7bb0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (2351, 6) \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Strain</th>\n",
       "      <th>Type</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Effects</th>\n",
       "      <th>Flavor</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100-Og</td>\n",
       "      <td>hybrid</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Creative,Energetic,Tingly,Euphoric,Relaxed</td>\n",
       "      <td>Earthy,Sweet,Citrus</td>\n",
       "      <td>$100 OG is a 50/50 hybrid strain that packs a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>98-White-Widow</td>\n",
       "      <td>hybrid</td>\n",
       "      <td>4.7</td>\n",
       "      <td>Relaxed,Aroused,Creative,Happy,Energetic</td>\n",
       "      <td>Flowery,Violet,Diesel</td>\n",
       "      <td>The ‘98 Aloha White Widow is an especially pot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1024</td>\n",
       "      <td>sativa</td>\n",
       "      <td>4.4</td>\n",
       "      <td>Uplifted,Happy,Relaxed,Energetic,Creative</td>\n",
       "      <td>Spicy/Herbal,Sage,Woody</td>\n",
       "      <td>1024 is a sativa-dominant hybrid bred in Spain...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13-Dawgs</td>\n",
       "      <td>hybrid</td>\n",
       "      <td>4.2</td>\n",
       "      <td>Tingly,Creative,Hungry,Relaxed,Uplifted</td>\n",
       "      <td>Apricot,Citrus,Grapefruit</td>\n",
       "      <td>13 Dawgs is a hybrid of G13 and Chemdawg genet...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24K-Gold</td>\n",
       "      <td>hybrid</td>\n",
       "      <td>4.6</td>\n",
       "      <td>Happy,Relaxed,Euphoric,Uplifted,Talkative</td>\n",
       "      <td>Citrus,Earthy,Orange</td>\n",
       "      <td>Also known as Kosher Tangie, 24k Gold is a 60%...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Strain    Type  Rating                                     Effects  \\\n",
       "0          100-Og  hybrid     4.0  Creative,Energetic,Tingly,Euphoric,Relaxed   \n",
       "1  98-White-Widow  hybrid     4.7    Relaxed,Aroused,Creative,Happy,Energetic   \n",
       "2            1024  sativa     4.4   Uplifted,Happy,Relaxed,Energetic,Creative   \n",
       "3        13-Dawgs  hybrid     4.2     Tingly,Creative,Hungry,Relaxed,Uplifted   \n",
       "4        24K-Gold  hybrid     4.6   Happy,Relaxed,Euphoric,Uplifted,Talkative   \n",
       "\n",
       "                      Flavor  \\\n",
       "0        Earthy,Sweet,Citrus   \n",
       "1      Flowery,Violet,Diesel   \n",
       "2    Spicy/Herbal,Sage,Woody   \n",
       "3  Apricot,Citrus,Grapefruit   \n",
       "4       Citrus,Earthy,Orange   \n",
       "\n",
       "                                         Description  \n",
       "0  $100 OG is a 50/50 hybrid strain that packs a ...  \n",
       "1  The ‘98 Aloha White Widow is an especially pot...  \n",
       "2  1024 is a sativa-dominant hybrid bred in Spain...  \n",
       "3  13 Dawgs is a hybrid of G13 and Chemdawg genet...  \n",
       "4  Also known as Kosher Tangie, 24k Gold is a 60%...  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/bundickm/Study-Guides/master/data/cannabis.csv')\n",
    "print('Shape:', df.shape, '\\n')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Zbpf-sf-DjRi"
   },
   "source": [
    "# Tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "S8pe3aGUJUkI"
   },
   "source": [
    "## Definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "C3GHPBZ4I3h5"
   },
   "source": [
    "Define the following terms in your own words, do not simply copy and paste a definition found elsewhere but reword it to be understandable and memorable to you. *Double click the markdown to add your definitions.*\n",
    "<br/><br/>\n",
    "\n",
    "**Natural Language Processing**: `Natural Language Processing is a branch of artificial intelligence that deals with the interaction between computers and humans using the natural language.Most NLP techniques rely on machine learning to derive meaning from human languages.`\n",
    "\n",
    "**Token**: `A token is an instance of a sequence of characters in some particular document that are grouped together as a useful semantic unit for processing.`\n",
    "\n",
    "**Corpus**: `In linguistics and NLP, corpus (literally Latin for body) refers to a collection of texts.`\n",
    "\n",
    "**Stopwords**: `In NLP, useless words (data), are referred to as stop words. A stop word is a commonly used word (such as “the”, “a”, “an”, “in”) that a search engine has been programmed to ignore, both when indexing entries for searching and when retrieving them as the result of a search query`\n",
    "\n",
    "**Statistical Trimming**: `Your Answer Here`\n",
    "\n",
    "**Stemming**: `Stemming is the process of reducing inflected (or sometimes derived) words to their word stem, base or root form—generally a written word form.`\n",
    "\n",
    "**Lemmatization**: `Lemmatization is a dictionary based technique. Therefore, Lemmatization is more accurate on the other hand it is slow in processing as it has to look up the dictionary. The base form of a word in this case is called Lemma.`\n",
    "\n",
    "**Vectorization**: `Word Embeddings or Word vectorization is a methodology in NLP to map words or phrases from vocabulary to a corresponding vector of real numbers which are used to find word predictions, word similarities/semantics.`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jbXlWbA3JWuU"
   },
   "source": [
    "## Questions of Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yjm-Ab4sJaOs"
   },
   "source": [
    "1. What are at least 4 common cleaning tasks you need to do when creating tokens?\n",
    " 1. `Case normalization`\n",
    " 2. `Keeping only alphanumeric characters`\n",
    " 3. `Removing stop words`\n",
    " 4. `Statistical trimming`\n",
    "\n",
    "2. Why is it important to apply custom stopwords to our dataset in addition to the ones that come in a library like spaCy?\n",
    "```\n",
    "Because the stop words are often unique to the context of the project.\n",
    "```\n",
    "\n",
    "3. Explain the tradeoffs between statistical trimming, stemming, and lemmatizing.\n",
    "```\n",
    "Stemming, as the name represents, finds the stem of a word. Example, stem of 'going' is 'go'. In stemming, the base form of a word is identified by chopping the word. Lemmatization is also used for the same purpose but it is more accurate than stemming. Therefore, Lemmatization is more accurate on the other hand it is slow in processing as it has to look up the dictionary. Statistical trimming \"trims\" the outliers in an attempt to collect only the most impactful data.\n",
    "```\n",
    "\n",
    "4. Why do we need to vectorize our documents?\n",
    "```\n",
    "Because the ML algorithms process math - not language in its natural form.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fn3Z587YMwnE"
   },
   "source": [
    "## Practice Problems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ii_LYpeoDrTp"
   },
   "source": [
    "Write a function to tokenize the `Description` column. Make sure to include the following:\n",
    "- Return the tokens in an iterable structure\n",
    "- Normalize the case\n",
    "- Remove non-alphanumeric characters such as punctuation, whitespace, unicode, etc.\n",
    "- Apply stopwords and make sure to add stopwords specific to this dataset\n",
    "- Lemmatize the tokens before returning them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import re\n",
    "# def tokenize(text):\n",
    "#     tokens = text.lower().split()\n",
    "#     tokens = re.sub('[^a-zA-Z 0-9]', '', text)\n",
    "#     return tokens\n",
    "\n",
    "# df['tokens'] = df['Description'].apply(tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Strain         0\n",
       "Type           0\n",
       "Rating         0\n",
       "Effects        0\n",
       "Flavor         0\n",
       "Description    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Description\"].fillna( method ='ffill', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Flavor\"].fillna( method ='ffill', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "STOP_WORDS = ['strain','effects']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pX8ZRE7fFqcw"
   },
   "source": [
    "Apply your function to `Description` and save the resulting tokens in a new column, `Tokens`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rgt9aT-TDFcq"
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.tokenizer import Tokenizer\n",
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "tokenizer = Tokenizer(nlp.vocab)\n",
    "\n",
    "def spacey_pipe_toke(df, STOP_WORDS):\n",
    "    \"\"\"\n",
    "    Takes dataframe['and_column'] as input\n",
    "    Along with a list of stop words -\n",
    "    Returns a tokenized column.\n",
    "    Couldnt figure out how to fit in lemma.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    sw = nlp.Defaults.stop_words.union(STOP_WORDS)\n",
    "    tokens = []\n",
    "    for doc in tokenizer.pipe(df, batch_size=500):   \n",
    "        doc_tokens = []   \n",
    "        for token in doc: \n",
    "            if ((token.text.lower() not in sw) and (token.is_stop != True) and (token.pos_ != 'PRON')) and (token.is_punct !=True) and (token.is_space != True):\n",
    "                doc_tokens.append(token.lemma_.strip().lower())\n",
    "\n",
    "        tokens.append(doc_tokens)    \n",
    "    df['tokens'] = tokens    \n",
    "    return df['tokens']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tokens'] = spacey_pipe_toke(df['Description'], STOP_WORDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Strain</th>\n",
       "      <th>Type</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Effects</th>\n",
       "      <th>Flavor</th>\n",
       "      <th>Description</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100-Og</td>\n",
       "      <td>hybrid</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Creative,Energetic,Tingly,Euphoric,Relaxed</td>\n",
       "      <td>Earthy,Sweet,Citrus</td>\n",
       "      <td>$100 OG is a 50/50 hybrid strain that packs a ...</td>\n",
       "      <td>[$100, og, 50/50, hybrid, pack, strong, punch....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>98-White-Widow</td>\n",
       "      <td>hybrid</td>\n",
       "      <td>4.7</td>\n",
       "      <td>Relaxed,Aroused,Creative,Happy,Energetic</td>\n",
       "      <td>Flowery,Violet,Diesel</td>\n",
       "      <td>The ‘98 Aloha White Widow is an especially pot...</td>\n",
       "      <td>[‘98, aloha, white, widow, especially, potent,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1024</td>\n",
       "      <td>sativa</td>\n",
       "      <td>4.4</td>\n",
       "      <td>Uplifted,Happy,Relaxed,Energetic,Creative</td>\n",
       "      <td>Spicy/Herbal,Sage,Woody</td>\n",
       "      <td>1024 is a sativa-dominant hybrid bred in Spain...</td>\n",
       "      <td>[1024, sativa-dominant, hybrid, breed, spain, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13-Dawgs</td>\n",
       "      <td>hybrid</td>\n",
       "      <td>4.2</td>\n",
       "      <td>Tingly,Creative,Hungry,Relaxed,Uplifted</td>\n",
       "      <td>Apricot,Citrus,Grapefruit</td>\n",
       "      <td>13 Dawgs is a hybrid of G13 and Chemdawg genet...</td>\n",
       "      <td>[13, dawgs, hybrid, g13, chemdawg, genetic, br...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24K-Gold</td>\n",
       "      <td>hybrid</td>\n",
       "      <td>4.6</td>\n",
       "      <td>Happy,Relaxed,Euphoric,Uplifted,Talkative</td>\n",
       "      <td>Citrus,Earthy,Orange</td>\n",
       "      <td>Also known as Kosher Tangie, 24k Gold is a 60%...</td>\n",
       "      <td>[know, kosher, tangie,, 24k, gold, 60%, indica...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2346</th>\n",
       "      <td>Zeus-Og</td>\n",
       "      <td>hybrid</td>\n",
       "      <td>4.7</td>\n",
       "      <td>Happy,Uplifted,Relaxed,Euphoric,Energetic</td>\n",
       "      <td>Earthy,Woody,Pine</td>\n",
       "      <td>Zeus OG is a hybrid cross between Pineapple OG...</td>\n",
       "      <td>[zeus, og, hybrid, cross, pineapple, og, deadh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2347</th>\n",
       "      <td>Zkittlez</td>\n",
       "      <td>indica</td>\n",
       "      <td>4.6</td>\n",
       "      <td>Relaxed,Happy,Euphoric,Uplifted,Sleepy</td>\n",
       "      <td>Sweet,Berry,Grape</td>\n",
       "      <td>Zkittlez is an indica-dominant mix of Grape Ap...</td>\n",
       "      <td>[zkittlez, indica-dominant, mix, grape, ape, g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2348</th>\n",
       "      <td>Zombie-Kush</td>\n",
       "      <td>indica</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Relaxed,Sleepy,Talkative,Euphoric,Happy</td>\n",
       "      <td>Earthy,Sweet,Spicy/Herbal</td>\n",
       "      <td>Zombie Kush by Ripper Seeds comes from two dif...</td>\n",
       "      <td>[zombie, kush, ripper, seeds, come, different,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2349</th>\n",
       "      <td>Zombie-Og</td>\n",
       "      <td>indica</td>\n",
       "      <td>4.4</td>\n",
       "      <td>Relaxed,Sleepy,Euphoric,Happy,Hungry</td>\n",
       "      <td>Sweet,Earthy,Pungent</td>\n",
       "      <td>If you’re looking to transform into a flesh-ea...</td>\n",
       "      <td>[you’re, look, transform, flesh-eating, monste...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2350</th>\n",
       "      <td>Zoom-Pie</td>\n",
       "      <td>indica</td>\n",
       "      <td>4.6</td>\n",
       "      <td>Hungry,Relaxed,Uplifted,Happy,Sleepy</td>\n",
       "      <td>Berry,Earthy,Pungent</td>\n",
       "      <td>Zoom Pie (also known as Zombie Pie) is a heavy...</td>\n",
       "      <td>[zoom, pie, (also, know, zombie, pie), heavy, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2351 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Strain    Type  Rating  \\\n",
       "0             100-Og  hybrid     4.0   \n",
       "1     98-White-Widow  hybrid     4.7   \n",
       "2               1024  sativa     4.4   \n",
       "3           13-Dawgs  hybrid     4.2   \n",
       "4           24K-Gold  hybrid     4.6   \n",
       "...              ...     ...     ...   \n",
       "2346         Zeus-Og  hybrid     4.7   \n",
       "2347        Zkittlez  indica     4.6   \n",
       "2348     Zombie-Kush  indica     5.0   \n",
       "2349       Zombie-Og  indica     4.4   \n",
       "2350        Zoom-Pie  indica     4.6   \n",
       "\n",
       "                                         Effects                     Flavor  \\\n",
       "0     Creative,Energetic,Tingly,Euphoric,Relaxed        Earthy,Sweet,Citrus   \n",
       "1       Relaxed,Aroused,Creative,Happy,Energetic      Flowery,Violet,Diesel   \n",
       "2      Uplifted,Happy,Relaxed,Energetic,Creative    Spicy/Herbal,Sage,Woody   \n",
       "3        Tingly,Creative,Hungry,Relaxed,Uplifted  Apricot,Citrus,Grapefruit   \n",
       "4      Happy,Relaxed,Euphoric,Uplifted,Talkative       Citrus,Earthy,Orange   \n",
       "...                                          ...                        ...   \n",
       "2346   Happy,Uplifted,Relaxed,Euphoric,Energetic          Earthy,Woody,Pine   \n",
       "2347      Relaxed,Happy,Euphoric,Uplifted,Sleepy          Sweet,Berry,Grape   \n",
       "2348     Relaxed,Sleepy,Talkative,Euphoric,Happy  Earthy,Sweet,Spicy/Herbal   \n",
       "2349        Relaxed,Sleepy,Euphoric,Happy,Hungry       Sweet,Earthy,Pungent   \n",
       "2350        Hungry,Relaxed,Uplifted,Happy,Sleepy       Berry,Earthy,Pungent   \n",
       "\n",
       "                                            Description  \\\n",
       "0     $100 OG is a 50/50 hybrid strain that packs a ...   \n",
       "1     The ‘98 Aloha White Widow is an especially pot...   \n",
       "2     1024 is a sativa-dominant hybrid bred in Spain...   \n",
       "3     13 Dawgs is a hybrid of G13 and Chemdawg genet...   \n",
       "4     Also known as Kosher Tangie, 24k Gold is a 60%...   \n",
       "...                                                 ...   \n",
       "2346  Zeus OG is a hybrid cross between Pineapple OG...   \n",
       "2347  Zkittlez is an indica-dominant mix of Grape Ap...   \n",
       "2348  Zombie Kush by Ripper Seeds comes from two dif...   \n",
       "2349  If you’re looking to transform into a flesh-ea...   \n",
       "2350  Zoom Pie (also known as Zombie Pie) is a heavy...   \n",
       "\n",
       "                                                 tokens  \n",
       "0     [$100, og, 50/50, hybrid, pack, strong, punch....  \n",
       "1     [‘98, aloha, white, widow, especially, potent,...  \n",
       "2     [1024, sativa-dominant, hybrid, breed, spain, ...  \n",
       "3     [13, dawgs, hybrid, g13, chemdawg, genetic, br...  \n",
       "4     [know, kosher, tangie,, 24k, gold, 60%, indica...  \n",
       "...                                                 ...  \n",
       "2346  [zeus, og, hybrid, cross, pineapple, og, deadh...  \n",
       "2347  [zkittlez, indica-dominant, mix, grape, ape, g...  \n",
       "2348  [zombie, kush, ripper, seeds, come, different,...  \n",
       "2349  [you’re, look, transform, flesh-eating, monste...  \n",
       "2350  [zoom, pie, (also, know, zombie, pie), heavy, ...  \n",
       "\n",
       "[2351 rows x 7 columns]"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       [$100, og, 50/50, hybrid, pack, strong, punch....\n",
       "1       [‘98, aloha, white, widow, especially, potent,...\n",
       "2       [1024, sativa-dominant, hybrid, breed, spain, ...\n",
       "3       [13, dawgs, hybrid, g13, chemdawg, genetic, br...\n",
       "4       [know, kosher, tangie,, 24k, gold, 60%, indica...\n",
       "                              ...                        \n",
       "2346    [zeus, og, hybrid, cross, pineapple, og, deadh...\n",
       "2347    [zkittlez, indica-dominant, mix, grape, ape, g...\n",
       "2348    [zombie, kush, ripper, seeds, come, different,...\n",
       "2349    [you’re, look, transform, flesh-eating, monste...\n",
       "2350    [zoom, pie, (also, know, zombie, pie), heavy, ...\n",
       "Name: tokens, Length: 2351, dtype: object"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tokens']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('hybrid', 1149),\n",
       " ('cross', 1010),\n",
       " ('og', 898),\n",
       " ('aroma', 748),\n",
       " ('kush', 723),\n",
       " ('indica', 697),\n",
       " ('sweet', 661),\n",
       " ('bud', 640),\n",
       " ('flower', 608),\n",
       " ('sativa', 575)]"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Object from Base Python\n",
    "from collections import Counter\n",
    "\n",
    "# The object `Counter` takes an iterable, but you can instaniate an empty one and update it. \n",
    "word_counts = Counter()\n",
    "\n",
    "# Update it based on a split of each of our documents\n",
    "df['tokens'].apply(lambda x: word_counts.update(x))\n",
    "\n",
    "# Print out the 10 most common words\n",
    "word_counts.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "M4x9xuBVF4Nh"
   },
   "source": [
    "Use the function below to create a `word_count` dataframe based off the `df['Tokens']` column you created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6zu2dfbcGz2Y"
   },
   "outputs": [],
   "source": [
    "def count(docs):\n",
    "        word_counts = Counter()\n",
    "        appears_in = Counter()\n",
    "        total_docs = len(docs)\n",
    "\n",
    "        for doc in docs:\n",
    "            word_counts.update(doc)\n",
    "            appears_in.update(set(doc))\n",
    "\n",
    "        temp = zip(word_counts.keys(), word_counts.values())\n",
    "        wc = pd.DataFrame(temp, columns = ['word', 'count'])\n",
    "\n",
    "        wc['rank'] = wc['count'].rank(method='first', ascending=False)\n",
    "        total = wc['count'].sum()\n",
    "\n",
    "        wc['pct_total'] = wc['count'].apply(lambda x: x / total)\n",
    "        \n",
    "        wc = wc.sort_values(by='rank')\n",
    "        wc['cul_pct_total'] = wc['pct_total'].cumsum()\n",
    "\n",
    "        t2 = zip(appears_in.keys(), appears_in.values())\n",
    "        ac = pd.DataFrame(t2, columns=['word', 'appears_in'])\n",
    "        wc = ac.merge(wc, on='word')\n",
    "\n",
    "        wc['appears_in_pct'] = wc['appears_in'].apply(lambda x: x / total_docs)\n",
    "        \n",
    "        return wc.sort_values(by='rank')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_count = count(df['tokens'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JPPxVzGIHUF8"
   },
   "source": [
    "Run the line of code below, and then explain how to interpret the graph.\n",
    "\n",
    "```\n",
    "Your Answer Here\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DWqbuy68Ib0S"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "sns.lineplot(x='rank', y='cul_pct_total', data=word_count);\n",
    "\n",
    "\n",
    "# It looks that under 200 words represent about 80% of all words in the corpus.\n",
    "# Often means we could benefit from trimming the extremities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "I-_e03NrMjIO"
   },
   "source": [
    "# Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(\"Spacy SHOULD be able to Handle most weird stuf\")\n",
    "exa = pd.DataFrame()\n",
    "for token in doc:\n",
    "    tmp = pd.DataFrame({f\"text\": token.text,\n",
    "                        \"lemma_\": token.lemma_,\n",
    "                        \"pos_\": token.pos_,\n",
    "                        \"tag_\": token.tag_,\n",
    "                        \"dep_\": token.dep_,\n",
    "                        \"shape\": token.shape_,\n",
    "                        \"is_alpha\": token.is_alpha,\n",
    "                        \"is_stop\": token.is_stop\n",
    "                        },\n",
    "                       index=[f\"{token}\"]\n",
    "                       )\n",
    "    exa = pd.concat([exa, tmp])\n",
    "exa.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tQRlWI7UM4ah"
   },
   "source": [
    "## Definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "djODVPGjM4ao"
   },
   "source": [
    "Define the following terms in your own words, do not simply copy and paste a definition found elsewhere but reword it to be understandable and memorable to you. *Double click the markdown to add your definitions.*\n",
    "<br/><br/>\n",
    "\n",
    "**Vectorization**: `Word Embeddings or Word vectorization is a methodology in NLP to map words or phrases from vocabulary to a corresponding vector of real numbers which are used to find word predictions, word similarities/semantics`\n",
    "\n",
    "**Document Term Matrix (DTM)**: `A document-term matrix or term-document matrix is a mathematical matrix that describes the frequency of terms that occur in a collection of documents. In a document-term matrix, rows correspond to documents in the collection and columns correspond to terms.`\n",
    "\n",
    "**Latent Semantic Analysis**: `Latent semantic analysis (LSA) is a technique in natural language processing, in particular distributional semantics, of analyzing relationships between a set of documents and the terms they contain by producing a set of concepts related to the documents and terms. LSA assumes that words that are close in meaning will occur in similar pieces of text (the distributional hypothesis)`\n",
    "\n",
    "**Term Frequency - Inverse Document Frequency (TF-IDF)**: `The tf–idf value increases proportionally to the number of times a word appears in the document and is offset by the number of documents in the corpus that contain the word, which helps to adjust for the fact that some words appear more frequently in general.`\n",
    "\n",
    "**Word Embedding**: `Word embeddings are a type of word representation that allows words with similar meaning to have a similar representation.`\n",
    "\n",
    "**N-Gram**: `In the fields of computational linguistics and probability, an n-gram is a contiguous sequence of n items from a given sample of text or speech. The items can be phonemes, syllables, letters, words or base pairs according to the application. The n-grams typically are collected from a text or speech corpus.`\n",
    "\n",
    "**Skip-Gram**: `Skip-gram is used to predict the context word for a given target word.`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lOsi6xE4M-cS"
   },
   "source": [
    "## Questions of Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3_Atsw1bM-cY"
   },
   "source": [
    "1. Why do we need to vectorize our documents?\n",
    "```\n",
    "Computers do not understand text and the relations between words and sentences, so you need a way to represent these words with numbers which is what computers understand.\n",
    "```\n",
    "\n",
    "2. How is TF-IDF different from simple word frequency? Why do we use TF-IDF over word frequency?\n",
    "```\n",
    "With TF-IDF, words are given weight – TF-IDF measures relevance, not frequency. That is, wordcounts are replaced with TF-IDF scores across the whole dataset.\n",
    "```\n",
    "\n",
    "3. Why might we choose a word embedding approach over a bag-of-words approach when it comes to vectorization?\n",
    "```\n",
    "To preserve the interalational aspect of the words as they become numbers.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SogHDgfhMTsc"
   },
   "source": [
    "## Practice Problems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "a7QrjSwIMYzB"
   },
   "source": [
    "Use the dataframe `df` above to complete the following."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1BTQbHxIMeQN"
   },
   "source": [
    "Vectorize the `Tokens` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mrmcd\\Anaconda3\\envs\\US4-S1-NLP\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:507: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\"The parameter 'token_pattern' will not be used\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "                lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "                ngram_range=(1, 1),\n",
       "                preprocessor=<function dummy at 0x000001E1D35CB268>,\n",
       "                stop_words=None, strip_accents=None,\n",
       "                token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                tokenizer=<function dummy at 0x000001E1D35CB268>,\n",
       "                vocabulary=None)"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "def dummy(doc):\n",
    "    return doc\n",
    "\n",
    "vect = CountVectorizer(\n",
    "        tokenizer=dummy,\n",
    "        preprocessor=dummy,\n",
    "    )  \n",
    "\n",
    "docs = df['tokens']\n",
    "\n",
    "vect.fit(docs)\n",
    "# cv.get_feature_names()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ka0AywjNMBMI"
   },
   "outputs": [],
   "source": [
    "dtm = vect.transform(df['tokens'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
       "                input='content', lowercase=True, max_df=1.0, max_features=None,\n",
       "                min_df=1, ngram_range=(1, 1), norm='l2',\n",
       "                preprocessor=<function tfidf_dummy at 0x000001E1D35CB048>,\n",
       "                smooth_idf=True, stop_words=None, strip_accents=None,\n",
       "                sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                tokenizer=<function tfidf_dummy at 0x000001E1D35CB048>,\n",
       "                use_idf=True, vocabulary=None)"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def tfidf_dummy(doc):\n",
    "    return doc\n",
    "\n",
    "tfidf_vect = TfidfVectorizer(\n",
    "        tokenizer=tfidf_dummy,\n",
    "        preprocessor=tfidf_dummy,\n",
    "    )  \n",
    "\n",
    "docs = df['tokens']\n",
    "\n",
    "tfidf_vect.fit(docs)\n",
    "# cv.get_feature_names()\n",
    "\n",
    "\n",
    "# tfidf = TfidfVectorizer()\n",
    "\n",
    "# dtm2 = tfidf.fit_transform(df['tokens'])\n",
    "\n",
    "# dtm_tfidf = pd.DataFrame(dtm.todense(), columns=vect.get_feature_names())\n",
    "\n",
    "# nn.fit(dtm2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtm2 = tfidf_vect.transform(df['tokens'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtm_df2 = pd.DataFrame(dtm2.todense(), columns=tfidf_vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NearestNeighbors(algorithm='kd_tree', leaf_size=30, metric='minkowski',\n",
       "                 metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
       "                 radius=1.0)"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.fit(dtm_df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "B26eq5wKMrF4"
   },
   "source": [
    "Build a Nearest Neighbors model from your dataframe and then find the 5 nearest neighbors to the strain \"100-OG\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JcwURJatMp7B"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NearestNeighbors(algorithm='kd_tree', leaf_size=30, metric='minkowski',\n",
       "                 metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
       "                 radius=1.0)"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##### Your Code Here #####\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "# Fit on DTM\n",
    "nn = NearestNeighbors(n_neighbors=5, algorithm='kd_tree')\n",
    "\n",
    "dtm_df = pd.DataFrame(dtm.todense(), columns=vect.get_feature_names())\n",
    "\n",
    "nn.fit(dtm_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "new = tfidf_vect.transform(strain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[1.        , 1.        , 1.        , 1.        , 1.08718181]]),\n",
       " array([[1652, 1653, 1749, 1651, 1488]], dtype=int64))"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.kneighbors(new.todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "#1          0\n",
       "#1,         0\n",
       "#1.         0\n",
       "#10         0\n",
       "#10,        0\n",
       "           ..\n",
       "“white”     0\n",
       "“wookie”    0\n",
       "“wtf!”      0\n",
       "“y,”        0\n",
       "“z’s.”      0\n",
       "Name: 1488, Length: 12593, dtype: int64"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtm_df.iloc[1488]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.        , 6.70820393, 6.70820393, 6.70820393, 6.70820393]]),\n",
       " array([[   0, 1651,  191, 1653, 1652]], dtype=int64))"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.kneighbors([dtm_df.iloc[0].values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.        , 3.16227766, 3.16227766, 3.16227766, 3.16227766]]),\n",
       " array([[ 191, 1652, 1651, 1749, 1653]], dtype=int64))"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.kneighbors([dtm_df.iloc[191]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "strain = [\"100-OG\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PvGLfBxDW6D7"
   },
   "source": [
    "You will be putting together a classification model below, but before you do you'll need a baseline. Run the line of code below and then find the normalized value counts for the `Rating` column in `df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6zsEPQgRZKmH"
   },
   "outputs": [],
   "source": [
    "df['Rating'] = df['Rating'].round().astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RCPof-7VZOMt"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6022968949383242"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Rating'].value_counts(normalize=True).max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hboaEX03Z_w5"
   },
   "source": [
    "What is the baseline accuracy?\n",
    "```\n",
    "60%\n",
    "```\n",
    "\n",
    "Visualize the rating counts from above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9PGmJSMqZxo0"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(df['Rating']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WwPg1cpShKNA"
   },
   "source": [
    "Use your vectorized tokens in the `df` dataframe to train a classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Strain</th>\n",
       "      <th>Type</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Effects</th>\n",
       "      <th>Flavor</th>\n",
       "      <th>Description</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100-Og</td>\n",
       "      <td>hybrid</td>\n",
       "      <td>4</td>\n",
       "      <td>Creative,Energetic,Tingly,Euphoric,Relaxed</td>\n",
       "      <td>Earthy,Sweet,Citrus</td>\n",
       "      <td>$100 OG is a 50/50 hybrid strain that packs a ...</td>\n",
       "      <td>[$100, og, 50/50, hybrid, pack, strong, punch....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>98-White-Widow</td>\n",
       "      <td>hybrid</td>\n",
       "      <td>5</td>\n",
       "      <td>Relaxed,Aroused,Creative,Happy,Energetic</td>\n",
       "      <td>Flowery,Violet,Diesel</td>\n",
       "      <td>The ‘98 Aloha White Widow is an especially pot...</td>\n",
       "      <td>[‘98, aloha, white, widow, especially, potent,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1024</td>\n",
       "      <td>sativa</td>\n",
       "      <td>4</td>\n",
       "      <td>Uplifted,Happy,Relaxed,Energetic,Creative</td>\n",
       "      <td>Spicy/Herbal,Sage,Woody</td>\n",
       "      <td>1024 is a sativa-dominant hybrid bred in Spain...</td>\n",
       "      <td>[1024, sativa-dominant, hybrid, breed, spain, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13-Dawgs</td>\n",
       "      <td>hybrid</td>\n",
       "      <td>4</td>\n",
       "      <td>Tingly,Creative,Hungry,Relaxed,Uplifted</td>\n",
       "      <td>Apricot,Citrus,Grapefruit</td>\n",
       "      <td>13 Dawgs is a hybrid of G13 and Chemdawg genet...</td>\n",
       "      <td>[13, dawgs, hybrid, g13, chemdawg, genetic, br...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24K-Gold</td>\n",
       "      <td>hybrid</td>\n",
       "      <td>5</td>\n",
       "      <td>Happy,Relaxed,Euphoric,Uplifted,Talkative</td>\n",
       "      <td>Citrus,Earthy,Orange</td>\n",
       "      <td>Also known as Kosher Tangie, 24k Gold is a 60%...</td>\n",
       "      <td>[know, kosher, tangie,, 24k, gold, 60%, indica...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2346</th>\n",
       "      <td>Zeus-Og</td>\n",
       "      <td>hybrid</td>\n",
       "      <td>5</td>\n",
       "      <td>Happy,Uplifted,Relaxed,Euphoric,Energetic</td>\n",
       "      <td>Earthy,Woody,Pine</td>\n",
       "      <td>Zeus OG is a hybrid cross between Pineapple OG...</td>\n",
       "      <td>[zeus, og, hybrid, cross, pineapple, og, deadh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2347</th>\n",
       "      <td>Zkittlez</td>\n",
       "      <td>indica</td>\n",
       "      <td>5</td>\n",
       "      <td>Relaxed,Happy,Euphoric,Uplifted,Sleepy</td>\n",
       "      <td>Sweet,Berry,Grape</td>\n",
       "      <td>Zkittlez is an indica-dominant mix of Grape Ap...</td>\n",
       "      <td>[zkittlez, indica-dominant, mix, grape, ape, g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2348</th>\n",
       "      <td>Zombie-Kush</td>\n",
       "      <td>indica</td>\n",
       "      <td>5</td>\n",
       "      <td>Relaxed,Sleepy,Talkative,Euphoric,Happy</td>\n",
       "      <td>Earthy,Sweet,Spicy/Herbal</td>\n",
       "      <td>Zombie Kush by Ripper Seeds comes from two dif...</td>\n",
       "      <td>[zombie, kush, ripper, seeds, come, different,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2349</th>\n",
       "      <td>Zombie-Og</td>\n",
       "      <td>indica</td>\n",
       "      <td>4</td>\n",
       "      <td>Relaxed,Sleepy,Euphoric,Happy,Hungry</td>\n",
       "      <td>Sweet,Earthy,Pungent</td>\n",
       "      <td>If you’re looking to transform into a flesh-ea...</td>\n",
       "      <td>[you’re, look, transform, flesh-eating, monste...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2350</th>\n",
       "      <td>Zoom-Pie</td>\n",
       "      <td>indica</td>\n",
       "      <td>5</td>\n",
       "      <td>Hungry,Relaxed,Uplifted,Happy,Sleepy</td>\n",
       "      <td>Berry,Earthy,Pungent</td>\n",
       "      <td>Zoom Pie (also known as Zombie Pie) is a heavy...</td>\n",
       "      <td>[zoom, pie, (also, know, zombie, pie), heavy, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2351 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Strain    Type  Rating  \\\n",
       "0             100-Og  hybrid       4   \n",
       "1     98-White-Widow  hybrid       5   \n",
       "2               1024  sativa       4   \n",
       "3           13-Dawgs  hybrid       4   \n",
       "4           24K-Gold  hybrid       5   \n",
       "...              ...     ...     ...   \n",
       "2346         Zeus-Og  hybrid       5   \n",
       "2347        Zkittlez  indica       5   \n",
       "2348     Zombie-Kush  indica       5   \n",
       "2349       Zombie-Og  indica       4   \n",
       "2350        Zoom-Pie  indica       5   \n",
       "\n",
       "                                         Effects                     Flavor  \\\n",
       "0     Creative,Energetic,Tingly,Euphoric,Relaxed        Earthy,Sweet,Citrus   \n",
       "1       Relaxed,Aroused,Creative,Happy,Energetic      Flowery,Violet,Diesel   \n",
       "2      Uplifted,Happy,Relaxed,Energetic,Creative    Spicy/Herbal,Sage,Woody   \n",
       "3        Tingly,Creative,Hungry,Relaxed,Uplifted  Apricot,Citrus,Grapefruit   \n",
       "4      Happy,Relaxed,Euphoric,Uplifted,Talkative       Citrus,Earthy,Orange   \n",
       "...                                          ...                        ...   \n",
       "2346   Happy,Uplifted,Relaxed,Euphoric,Energetic          Earthy,Woody,Pine   \n",
       "2347      Relaxed,Happy,Euphoric,Uplifted,Sleepy          Sweet,Berry,Grape   \n",
       "2348     Relaxed,Sleepy,Talkative,Euphoric,Happy  Earthy,Sweet,Spicy/Herbal   \n",
       "2349        Relaxed,Sleepy,Euphoric,Happy,Hungry       Sweet,Earthy,Pungent   \n",
       "2350        Hungry,Relaxed,Uplifted,Happy,Sleepy       Berry,Earthy,Pungent   \n",
       "\n",
       "                                            Description  \\\n",
       "0     $100 OG is a 50/50 hybrid strain that packs a ...   \n",
       "1     The ‘98 Aloha White Widow is an especially pot...   \n",
       "2     1024 is a sativa-dominant hybrid bred in Spain...   \n",
       "3     13 Dawgs is a hybrid of G13 and Chemdawg genet...   \n",
       "4     Also known as Kosher Tangie, 24k Gold is a 60%...   \n",
       "...                                                 ...   \n",
       "2346  Zeus OG is a hybrid cross between Pineapple OG...   \n",
       "2347  Zkittlez is an indica-dominant mix of Grape Ap...   \n",
       "2348  Zombie Kush by Ripper Seeds comes from two dif...   \n",
       "2349  If you’re looking to transform into a flesh-ea...   \n",
       "2350  Zoom Pie (also known as Zombie Pie) is a heavy...   \n",
       "\n",
       "                                                 tokens  \n",
       "0     [$100, og, 50/50, hybrid, pack, strong, punch....  \n",
       "1     [‘98, aloha, white, widow, especially, potent,...  \n",
       "2     [1024, sativa-dominant, hybrid, breed, spain, ...  \n",
       "3     [13, dawgs, hybrid, g13, chemdawg, genetic, br...  \n",
       "4     [know, kosher, tangie,, 24k, gold, 60%, indica...  \n",
       "...                                                 ...  \n",
       "2346  [zeus, og, hybrid, cross, pineapple, og, deadh...  \n",
       "2347  [zkittlez, indica-dominant, mix, grape, ape, g...  \n",
       "2348  [zombie, kush, ripper, seeds, come, different,...  \n",
       "2349  [you’re, look, transform, flesh-eating, monste...  \n",
       "2350  [zoom, pie, (also, know, zombie, pie), heavy, ...  \n",
       "\n",
       "[2351 rows x 7 columns]"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "awu-ujvvhips"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;31mTypeError\u001b[0m: float() argument must be a string or a number, not 'list'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-199-932fff35cf53>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mrfc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mrfc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\US4-S1-NLP\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    293\u001b[0m         \"\"\"\n\u001b[0;32m    294\u001b[0m         \u001b[1;31m# Validate or convert input data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 295\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"csc\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    296\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'csc'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    297\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\US4-S1-NLP\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    529\u001b[0m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcasting\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"unsafe\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    530\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 531\u001b[1;33m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    532\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    533\u001b[0m                 raise ValueError(\"Complex data not supported\\n\"\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\US4-S1-NLP\\lib\\site-packages\\numpy\\core\\_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[1;34m(a, dtype, order)\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m     \"\"\"\n\u001b[1;32m---> 85\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     86\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\US4-S1-NLP\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m__array__\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m    752\u001b[0m               dtype='datetime64[ns]')\n\u001b[0;32m    753\u001b[0m         \"\"\"\n\u001b[1;32m--> 754\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    755\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    756\u001b[0m     \u001b[1;31m# ----------------------------------------------------------------------\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\US4-S1-NLP\\lib\\site-packages\\numpy\\core\\_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[1;34m(a, dtype, order)\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m     \"\"\"\n\u001b[1;32m---> 85\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     86\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\US4-S1-NLP\\lib\\site-packages\\pandas\\core\\arrays\\numpy_.py\u001b[0m in \u001b[0;36m__array__\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m    182\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    183\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__array__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 184\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ndarray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    185\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    186\u001b[0m     \u001b[0m_HANDLED_TYPES\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumbers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNumber\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\US4-S1-NLP\\lib\\site-packages\\numpy\\core\\_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[1;34m(a, dtype, order)\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m     \"\"\"\n\u001b[1;32m---> 85\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     86\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: setting an array element with a sequence."
     ]
    }
   ],
   "source": [
    "# Import Statements\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "data = df['Description']\n",
    "target = df['Description']\n",
    "\n",
    "vect = TfidfVectorizer(stop_words='english', ngram_range=(1,2), min_df=5)\n",
    "rfc = RandomForestClassifier()\n",
    "\n",
    "rfc.fit(data, target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#1</th>\n",
       "      <th>#1,</th>\n",
       "      <th>#1.</th>\n",
       "      <th>#10</th>\n",
       "      <th>#10,</th>\n",
       "      <th>#13</th>\n",
       "      <th>#18</th>\n",
       "      <th>#18,</th>\n",
       "      <th>#18.</th>\n",
       "      <th>#1’s</th>\n",
       "      <th>...</th>\n",
       "      <th>“ubc</th>\n",
       "      <th>“uk</th>\n",
       "      <th>“unholy”</th>\n",
       "      <th>“wait,</th>\n",
       "      <th>“warm</th>\n",
       "      <th>“white”</th>\n",
       "      <th>“wookie”</th>\n",
       "      <th>“wtf!”</th>\n",
       "      <th>“y,”</th>\n",
       "      <th>“z’s.”</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2346</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2347</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2348</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2349</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2350</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2351 rows × 12593 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      #1  #1,  #1.  #10  #10,  #13  #18  #18,  #18.  #1’s  ...  “ubc  “uk  \\\n",
       "0      0    0    0    0     0    0    0     0     0     0  ...     0    0   \n",
       "1      0    0    0    0     0    0    0     0     0     0  ...     0    0   \n",
       "2      0    0    0    0     0    0    0     0     0     0  ...     0    0   \n",
       "3      0    0    0    0     0    0    0     0     0     0  ...     0    0   \n",
       "4      0    0    0    0     0    0    0     0     0     0  ...     0    0   \n",
       "...   ..  ...  ...  ...   ...  ...  ...   ...   ...   ...  ...   ...  ...   \n",
       "2346   0    0    0    0     0    0    0     0     0     0  ...     0    0   \n",
       "2347   0    0    0    0     0    0    0     0     0     0  ...     0    0   \n",
       "2348   0    0    0    0     0    0    0     0     0     0  ...     0    0   \n",
       "2349   0    0    0    0     0    0    0     0     0     0  ...     0    0   \n",
       "2350   0    0    0    0     0    0    0     0     0     0  ...     0    0   \n",
       "\n",
       "      “unholy”  “wait,  “warm  “white”  “wookie”  “wtf!”  “y,”  “z’s.”  \n",
       "0            0       0      0        0         0       0     0       0  \n",
       "1            0       0      0        0         0       0     0       0  \n",
       "2            0       0      0        0         0       0     0       0  \n",
       "3            0       0      0        0         0       0     0       0  \n",
       "4            0       0      0        0         0       0     0       0  \n",
       "...        ...     ...    ...      ...       ...     ...   ...     ...  \n",
       "2346         0       0      0        0         0       0     0       0  \n",
       "2347         0       0      0        0         0       0     0       0  \n",
       "2348         0       0      0        0         0       0     0       0  \n",
       "2349         0       0      0        0         0       0     0       0  \n",
       "2350         0       0      0        0         0       0     0       0  \n",
       "\n",
       "[2351 rows x 12593 columns]"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtm_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "afgooey = [\"Afgooey, also known as Afgoo, is a potent indica strain that is believed to descend from an Afghani indica and Maui Haze. Its sativa parent may lend Afgoo some uplifting, creative qualities, but this strain undoubtedly takes after its indica parent as it primarily delivers relaxing, sleepy effects alongside its earthy pine flavor. Growers hoping to cultivate Afgoo may have a better chance of success indoors, but this indica can also thrive in Mediterranean climates outdoors.\" ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kGhSLJ5Fhlg9"
   },
   "source": [
    "Predict the score of the fake strain description below.\n",
    "\n",
    "```\n",
    "'Afgooey, also known as Afgoo, is a potent indica strain that is believed to descend from an Afghani indica and Maui Haze. \n",
    "Its sativa parent may lend Afgoo some uplifting, creative qualities, but this strain undoubtedly takes after its indica \n",
    "parent as it primarily delivers relaxing, sleepy effects alongside its earthy pine flavor. Growers hoping to cultivate Afgoo \n",
    "may have a better chance of success indoors, but this indica can also thrive in Mediterranean climates outdoors.'\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rAHaMGjBiG-h"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'Send me lots of money now'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-196-b0c2f3e3417f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mrfc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Send me lots of money now'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'you won the lottery in Nigeria'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\US4-S1-NLP\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    610\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0mclasses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    611\u001b[0m         \"\"\"\n\u001b[1;32m--> 612\u001b[1;33m         \u001b[0mproba\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    613\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    614\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\US4-S1-NLP\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    654\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    655\u001b[0m         \u001b[1;31m# Check data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 656\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    657\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    658\u001b[0m         \u001b[1;31m# Assign chunk of trees to jobs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\US4-S1-NLP\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36m_validate_X_predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    410\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    411\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 412\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    413\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    414\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\US4-S1-NLP\\lib\\site-packages\\sklearn\\tree\\_classes.py\u001b[0m in \u001b[0;36m_validate_X_predict\u001b[1;34m(self, X, check_input)\u001b[0m\n\u001b[0;32m    378\u001b[0m         \u001b[1;34m\"\"\"Validate X whenever one tries to predict, apply, predict_proba\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    379\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 380\u001b[1;33m             \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"csr\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    381\u001b[0m             if issparse(X) and (X.indices.dtype != np.intc or\n\u001b[0;32m    382\u001b[0m                                 X.indptr.dtype != np.intc):\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\US4-S1-NLP\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    529\u001b[0m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcasting\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"unsafe\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    530\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 531\u001b[1;33m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    532\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    533\u001b[0m                 raise ValueError(\"Complex data not supported\\n\"\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\US4-S1-NLP\\lib\\site-packages\\numpy\\core\\_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[1;34m(a, dtype, order)\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m     \"\"\"\n\u001b[1;32m---> 85\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     86\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'Send me lots of money now'"
     ]
    }
   ],
   "source": [
    "rfc.predict(['Send me lots of money now', 'you won the lottery in Nigeria'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RGnLTUL8ik4V"
   },
   "source": [
    "# Topic Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rfXxSZSDk-Sh"
   },
   "source": [
    "## Questions of Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hlcEfmnyk-St"
   },
   "source": [
    "1. What is Latent Dirichlet Allocation? What is another name for LDA in NLP?\n",
    "```\n",
    "Your Answer Here\n",
    "```\n",
    "\n",
    "2. How do interpret the results of a topic modeling output?\n",
    "```\n",
    "Your Answer Here\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lAf8cmNFl_n5"
   },
   "source": [
    "## Practice Problems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RIeP8NyHmAU8"
   },
   "source": [
    "Find the top 5 topics of the `Description` column using LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "e-8zDKA_mAba"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ADcqbM9FmiVg"
   },
   "source": [
    "In a short paragraph, explain how to interpret the first topic your model came up with. If your topic words are difficult to interpret, explain how you could clean up the descriptions to improve your topics\n",
    "\n",
    "```\n",
    "Your Answer Here\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "suchG0sEm8lU"
   },
   "source": [
    "Use `pyLDAvis` to create a visualization to help you interpret your topic modeling results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3f5LbisKnRPV"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HafoLqwHnR5M"
   },
   "source": [
    "Explain how to interpret the results of `pyLDAvis`\n",
    "\n",
    "```\n",
    "Your Answer Here\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ANxVUGU2nYsB"
   },
   "source": [
    "Create at least 1 more visualization to help you interpret the results of your topic modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WEsF_ZMIm7mC"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Unit_4_Sprint_1_Natural_Language_Processing_Study_Guide.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "U4-S1-NLP (Python3)",
   "language": "python",
   "name": "u4-s1-nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
