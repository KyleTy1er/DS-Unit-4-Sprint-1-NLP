{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lambda School Data Science\n",
    "\n",
    "*Unit 4, Sprint 1, Module 3*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Document Classification (Assignment)\n",
    "\n",
    "This notebook is for you to practice skills during lecture.\n",
    "\n",
    "Today's guided module project and assignment will be different. You already know how to do classification. You ready know how to extract features from documents. So? That means you're ready to combine and practice those skills in a kaggle competition. We we will open with a five minute sprint explaining the competition, and then give you 25 minutes to work. After those twenty five minutes are up, I will give a 5-minute demo an NLP technique that will help you with document classification (*and **maybe** the competition*).\n",
    "\n",
    "Today's all about having fun and practicing your skills.\n",
    "\n",
    "## Sections\n",
    "* <a href=\"#p1\">Part 1</a>: Text Feature Extraction & Classification Pipelines\n",
    "* <a href=\"#p2\">Part 2</a>: Latent Semantic Indexing\n",
    "* <a href=\"#p3\">Part 3</a>: Word Embeddings with Spacy\n",
    "* <a href=\"#p4\">Part 4</a>: Post Lecture Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Feature Extraction & Classification Pipelines (Learn)\n",
    "<a id=\"p1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "## Follow Along \n",
    "\n",
    "What you should be doing now:\n",
    "1. Join the Kaggle Competition\n",
    "2. Download the data\n",
    "3. Train a model (try using the pipe method I just demoed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Competition Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Statements\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.decomposition import TruncatedSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# You may need to change the path\n",
    "train = pd.read_csv('./data/train.csv')\n",
    "test = pd.read_csv('./data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>description</th>\n",
       "      <th>ratingCategory</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1321</td>\n",
       "      <td>\\nSometimes, when whisky is batched, a few lef...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3861</td>\n",
       "      <td>\\nAn uncommon exclusive bottling of a 6 year o...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>655</td>\n",
       "      <td>\\nThis release is a port version of Amrut’s In...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>555</td>\n",
       "      <td>\\nThis 41 year old single cask was aged in a s...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1965</td>\n",
       "      <td>\\nQuite herbal on the nose, with aromas of dri...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id                                        description  ratingCategory\n",
       "0  1321  \\nSometimes, when whisky is batched, a few lef...               1\n",
       "1  3861  \\nAn uncommon exclusive bottling of a 6 year o...               0\n",
       "2   655  \\nThis release is a port version of Amrut’s In...               1\n",
       "3   555  \\nThis 41 year old single cask was aged in a s...               1\n",
       "4  1965  \\nQuite herbal on the nose, with aromas of dri...               1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Pipeline Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = TfidfVectorizer(stop_words='english', ngram_range=(1,2), min_df=5)\n",
    "rfc = RandomForestClassifier()\n",
    "\n",
    "\n",
    "# Define the Pipeline\n",
    "pipe = Pipeline([\n",
    "                 #Vectorizer\n",
    "                 ('vect', vect),\n",
    "                 # Classifier\n",
    "                 ('clf', rfc),\n",
    "                ])\n",
    "\n",
    "# The pipeline puts together a bunch fit then transform,fit then predict. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# attempt at second pipeline:\n",
    "\n",
    "# knn = NearestNeighbors(n_neighbors=5, algorithm='kd_tree')\n",
    "\n",
    "# pipe2 = Pipeline([\n",
    "#                  #Vectorizer\n",
    "#                  ('vect', vect),\n",
    "#                  ('knn', knn),\n",
    "#                 ])\n",
    "\n",
    "# parameters2 = {\n",
    "#     'vect__max_df': ( 0.75, 1.0),\n",
    "#     'vect__min_df': (.02, .05),\n",
    "#     'vect__max_features': (500,1000),\n",
    "#     'knn__n_neigbors': (5, 10)\n",
    "# }\n",
    "\n",
    "# grid_search = GridSearchCV(pipe2,parameters2, cv=5, n_jobs=-1, verbose=1)\n",
    "# grid_search.fit(data, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = train['description']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = train['ratingCategory']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Your Search Space\n",
    "You're looking for both the best hyperparameters of your vectorizer and your classification model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   14.6s\n",
      "[Parallel(n_jobs=-1)]: Done 160 out of 160 | elapsed:   48.7s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('vect',\n",
       "                                        TfidfVectorizer(analyzer='word',\n",
       "                                                        binary=False,\n",
       "                                                        decode_error='strict',\n",
       "                                                        dtype=<class 'numpy.float64'>,\n",
       "                                                        encoding='utf-8',\n",
       "                                                        input='content',\n",
       "                                                        lowercase=True,\n",
       "                                                        max_df=1.0,\n",
       "                                                        max_features=None,\n",
       "                                                        min_df=5,\n",
       "                                                        ngram_range=(1, 2),\n",
       "                                                        norm='l2',\n",
       "                                                        preprocessor=None,\n",
       "                                                        smooth_idf=True,\n",
       "                                                        stop_words='english',\n",
       "                                                        strip...\n",
       "                                                               n_jobs=None,\n",
       "                                                               oob_score=False,\n",
       "                                                               random_state=None,\n",
       "                                                               verbose=0,\n",
       "                                                               warm_start=False))],\n",
       "                                verbose=False),\n",
       "             iid='deprecated', n_jobs=-1,\n",
       "             param_grid={'clf__max_depth': (15, 20),\n",
       "                         'clf__n_estimators': (5, 10),\n",
       "                         'vect__max_df': (0.75, 1.0),\n",
       "                         'vect__max_features': (500, 1000),\n",
       "                         'vect__min_df': (0.02, 0.05)},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "parameters = {\n",
    "    'vect__max_df': ( 0.75, 1.0),\n",
    "    'vect__min_df': (.02, .05),\n",
    "    'vect__max_features': (500,1000),\n",
    "    'clf__n_estimators':(5, 10,),\n",
    "    'clf__max_depth':(15,20)\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(pipe,parameters, cv=5, n_jobs=-1, verbose=1)\n",
    "grid_search.fit(data, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7186205121605971"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1], dtype=int64)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.predict(['Send me lots of money now', 'you won the lottery in Nigeria'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make a Submission File\n",
    "*Note:* In a typical Kaggle competition, you are only allowed two submissions a day, so you only submit if you feel you cannot achieve higher test accuracy. For this competition the max daily submissions are capped at **20**. Submit for each demo and for your assignment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions on test sample\n",
    "pred = grid_search.predict(test['description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'id': test['id'], 'ratingCategory':pred})\n",
    "submission['ratingCategory'] = submission['ratingCategory'].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>ratingCategory</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3461</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2604</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3341</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3764</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2306</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id  ratingCategory\n",
       "0  3461               1\n",
       "1  2604               1\n",
       "2  3341               1\n",
       "3  3764               1\n",
       "4  2306               1"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make Sure the Category is an Integer\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "subNumber = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save your Submission File\n",
    "# Best to Use an Integer or Timestamp for different versions of your model\n",
    "\n",
    "submission.to_csv(f'./data/submission{subNumber}.csv', index=False)\n",
    "subNumber += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge\n",
    "\n",
    "You're trying to achieve a minimum of 70% Accuracy on your model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Latent Semantic Indexing (Learn)\n",
    "<a id=\"p2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "## Follow Along\n",
    "1. Join the Kaggle Competition\n",
    "2. Download the data\n",
    "3. Train a model & try: \n",
    "    - Creating a Text Extraction & Classification Pipeline\n",
    "    - Tune the pipeline with a `GridSearchCV` or `RandomizedSearchCV`\n",
    "    - Add some Latent Semantic Indexing (lsi) into your pipeline. *Note:* You can grid search a nested pipeline, but you have to use double underscores ie `lsi__svd__n_components`\n",
    "4. Make a submission to Kaggle \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Pipeline Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "svd = TruncatedSVD(n_components=100, # Just here for demo. \n",
    "                   algorithm='randomized',\n",
    "                   n_iter=10)\n",
    "\n",
    "params = { \n",
    "    'lsi__svd__n_components': [10,100,250, 400],\n",
    "    'lsi__vect__max_df':[.7, .9, .95, 1.0],\n",
    "    'clf__n_estimators':[2,5,10,20],\n",
    "    'clf__max_depth':(15,20, 25, 30)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSI\n",
    "lsi = Pipeline([('vect', vect), ('svd', svd)])\n",
    "\n",
    "\n",
    "# Pipe\n",
    "pipe = Pipeline([('lsi', lsi), ('clf', rfc)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(memory=None,\n",
      "         steps=[('vect',\n",
      "                 TfidfVectorizer(analyzer='word', binary=False,\n",
      "                                 decode_error='strict',\n",
      "                                 dtype=<class 'numpy.float64'>,\n",
      "                                 encoding='utf-8', input='content',\n",
      "                                 lowercase=True, max_df=1.0, max_features=None,\n",
      "                                 min_df=5, ngram_range=(1, 2), norm='l2',\n",
      "                                 preprocessor=None, smooth_idf=True,\n",
      "                                 stop_words='english', strip_accents=None,\n",
      "                                 sublinear_tf=False,\n",
      "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "                                 tokenizer=None, use_idf=True,\n",
      "                                 vocabulary=None)),\n",
      "                ('svd',\n",
      "                 TruncatedSVD(algorithm='randomized', n_components=100,\n",
      "                              n_iter=10, random_state=None, tol=0.0))],\n",
      "         verbose=False)\n"
     ]
    }
   ],
   "source": [
    "print(lsi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(memory=None,\n",
      "         steps=[('lsi',\n",
      "                 Pipeline(memory=None,\n",
      "                          steps=[('vect',\n",
      "                                  TfidfVectorizer(analyzer='word', binary=False,\n",
      "                                                  decode_error='strict',\n",
      "                                                  dtype=<class 'numpy.float64'>,\n",
      "                                                  encoding='utf-8',\n",
      "                                                  input='content',\n",
      "                                                  lowercase=True, max_df=1.0,\n",
      "                                                  max_features=None, min_df=5,\n",
      "                                                  ngram_range=(1, 2), norm='l2',\n",
      "                                                  preprocessor=None,\n",
      "                                                  smooth_idf=True,\n",
      "                                                  stop_words='english',\n",
      "                                                  strip_accents=...\n",
      "                 RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
      "                                        class_weight=None, criterion='gini',\n",
      "                                        max_depth=None, max_features='auto',\n",
      "                                        max_leaf_nodes=None, max_samples=None,\n",
      "                                        min_impurity_decrease=0.0,\n",
      "                                        min_impurity_split=None,\n",
      "                                        min_samples_leaf=1, min_samples_split=2,\n",
      "                                        min_weight_fraction_leaf=0.0,\n",
      "                                        n_estimators=100, n_jobs=None,\n",
      "                                        oob_score=False, random_state=None,\n",
      "                                        verbose=0, warm_start=False))],\n",
      "         verbose=False)\n"
     ]
    }
   ],
   "source": [
    "print(pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 256 candidates, totalling 1280 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   25.0s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:  6.8min\n",
      "[Parallel(n_jobs=-1)]: Done 792 tasks      | elapsed: 13.0min\n",
      "[Parallel(n_jobs=-1)]: Done 1242 tasks      | elapsed: 20.5min\n",
      "[Parallel(n_jobs=-1)]: Done 1280 out of 1280 | elapsed: 21.6min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('lsi',\n",
       "                                        Pipeline(memory=None,\n",
       "                                                 steps=[('vect',\n",
       "                                                         TfidfVectorizer(analyzer='word',\n",
       "                                                                         binary=False,\n",
       "                                                                         decode_error='strict',\n",
       "                                                                         dtype=<class 'numpy.float64'>,\n",
       "                                                                         encoding='utf-8',\n",
       "                                                                         input='content',\n",
       "                                                                         lowercase=True,\n",
       "                                                                         max_df=1.0,\n",
       "                                                                         max_features=None,\n",
       "                                                                         min_df=5,\n",
       "                                                                         ngram_range=(1,\n",
       "                                                                                      2),\n",
       "                                                                         norm='l2',\n",
       "                                                                         preprocessor=None,\n",
       "                                                                         smooth_...\n",
       "                                                               n_jobs=None,\n",
       "                                                               oob_score=False,\n",
       "                                                               random_state=None,\n",
       "                                                               verbose=0,\n",
       "                                                               warm_start=False))],\n",
       "                                verbose=False),\n",
       "             iid='deprecated', n_jobs=-1,\n",
       "             param_grid={'clf__max_depth': (15, 20, 25, 30),\n",
       "                         'clf__n_estimators': [2, 5, 10, 20],\n",
       "                         'lsi__svd__n_components': [10, 100, 250, 400],\n",
       "                         'lsi__vect__max_df': [0.7, 0.9, 0.95, 1.0]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=1)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit\n",
    "grid_search = GridSearchCV(pipe,params, cv=5, n_jobs=-1, verbose=1)\n",
    "grid_search.fit(data,target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7262092514506827"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Your Search Space\n",
    "You're looking for both the best hyperparameters of your vectorizer and your classification model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make a Submission File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions on test sample\n",
    "pred = grid_search.predict(test['description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'id': test['id'], 'ratingCategory':pred})\n",
    "submission['ratingCategory'] = submission['ratingCategory'].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>ratingCategory</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3461</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2604</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3341</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3764</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2306</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id  ratingCategory\n",
       "0  3461               1\n",
       "1  2604               1\n",
       "2  3341               1\n",
       "3  3764               1\n",
       "4  2306               1"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make Sure the Category is an Integer\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save your Submission File\n",
    "# Best to Use an Integer or Timestamp for different versions of your model\n",
    "\n",
    "submission.to_csv(f'./data/submission{subNumber}.csv', index=False)\n",
    "subNumber += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge\n",
    "\n",
    "Continue to apply Latent Semantic Indexing (LSI) to various datasets. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Embeddings with Spacy (Learn)\n",
    "<a id=\"p3\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "sns.countplot(train['ratingCategory']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UPSAMPLING EXAMPLE:\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.utils import resample\n",
    "# You may need to change the path\n",
    "train = pd.read_csv('./data/train.csv')\n",
    "test = pd.read_csv('./data/test.csv')\n",
    "minority = train[train['ratingCategory'] == 0]\n",
    "majority = train[train['ratingCategory'] == 1]\n",
    "df_minority_upsampled = resample(minority,\n",
    "                                 replace=True,\n",
    "                                 n_samples=majority.shape[0]\n",
    "                                )\n",
    "df_upsampled = pd.concat([majority, df_minority_upsampled])\n",
    "\n",
    "\n",
    "\n",
    "# DOWNSAMPLING EXAMPLE:\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.utils import resample\n",
    "# You may need to change the path\n",
    "train = pd.read_csv('./data/train.csv')\n",
    "test = pd.read_csv('./data/test.csv')\n",
    "minority = train[train['ratingCategory'] == 0]\n",
    "majority = train[train['ratingCategory'] == 1]\n",
    "df_majority_downsampled = resample(majority,\n",
    "                                 replace=False,\n",
    "                                 n_samples=minority.shape[0]\n",
    "                                )\n",
    "df_downsampled = pd.concat([minority, df_majority_downsampled])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Follow Along"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.utils import resample\n",
    "# You may need to change the path\n",
    "\n",
    "minority = train[train['ratingCategory'] == 0]\n",
    "majority = train[train['ratingCategory'] == 1]\n",
    "df_minority_upsampled = resample(minority,\n",
    "                                 replace=True,\n",
    "                                 n_samples=majority.shape[0]\n",
    "                                )\n",
    "df_upsampled = pd.concat([majority, df_minority_upsampled])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(df_upsampled['ratingCategory']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 256 candidates, totalling 1280 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Invalid parameter lsi for estimator Pipeline(memory=None,\n         steps=[('vect',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=True, max_df=1.0, max_features=None,\n                                 min_df=5, ngram_range=(1, 2), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_words='english', strip_accents=None,\n                                 sublinear_tf=False,\n                                 token_patte...\n                 RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n                                        class_weight=None, criterion='gini',\n                                        max_depth=None, max_features='auto',\n                                        max_leaf_nodes=None, max_samples=None,\n                                        min_impurity_decrease=0.0,\n                                        min_impurity_split=None,\n                                        min_samples_leaf=1, min_samples_split=2,\n                                        min_weight_fraction_leaf=0.0,\n                                        n_estimators=100, n_jobs=None,\n                                        oob_score=False, random_state=None,\n                                        verbose=0, warm_start=False))],\n         verbose=False). Check the list of available parameters with `estimator.get_params().keys()`.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"C:\\Users\\mrmcd\\Anaconda3\\envs\\US4-S1-NLP\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 418, in _process_worker\n    r = call_item()\n  File \"C:\\Users\\mrmcd\\Anaconda3\\envs\\US4-S1-NLP\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 272, in __call__\n    return self.fn(*self.args, **self.kwargs)\n  File \"C:\\Users\\mrmcd\\Anaconda3\\envs\\US4-S1-NLP\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 608, in __call__\n    return self.func(*args, **kwargs)\n  File \"C:\\Users\\mrmcd\\Anaconda3\\envs\\US4-S1-NLP\\lib\\site-packages\\joblib\\parallel.py\", line 256, in __call__\n    for func, args, kwargs in self.items]\n  File \"C:\\Users\\mrmcd\\Anaconda3\\envs\\US4-S1-NLP\\lib\\site-packages\\joblib\\parallel.py\", line 256, in <listcomp>\n    for func, args, kwargs in self.items]\n  File \"C:\\Users\\mrmcd\\Anaconda3\\envs\\US4-S1-NLP\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 504, in _fit_and_score\n    estimator = estimator.set_params(**cloned_parameters)\n  File \"C:\\Users\\mrmcd\\Anaconda3\\envs\\US4-S1-NLP\\lib\\site-packages\\sklearn\\pipeline.py\", line 163, in set_params\n    self._set_params('steps', **kwargs)\n  File \"C:\\Users\\mrmcd\\Anaconda3\\envs\\US4-S1-NLP\\lib\\site-packages\\sklearn\\utils\\metaestimators.py\", line 50, in _set_params\n    super().set_params(**params)\n  File \"C:\\Users\\mrmcd\\Anaconda3\\envs\\US4-S1-NLP\\lib\\site-packages\\sklearn\\base.py\", line 236, in set_params\n    (key, self))\nValueError: Invalid parameter lsi for estimator Pipeline(memory=None,\n         steps=[('vect',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=True, max_df=1.0, max_features=None,\n                                 min_df=5, ngram_range=(1, 2), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_words='english', strip_accents=None,\n                                 sublinear_tf=False,\n                                 token_patte...\n                 RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n                                        class_weight=None, criterion='gini',\n                                        max_depth=None, max_features='auto',\n                                        max_leaf_nodes=None, max_samples=None,\n                                        min_impurity_decrease=0.0,\n                                        min_impurity_split=None,\n                                        min_samples_leaf=1, min_samples_split=2,\n                                        min_weight_fraction_leaf=0.0,\n                                        n_estimators=100, n_jobs=None,\n                                        oob_score=False, random_state=None,\n                                        verbose=0, warm_start=False))],\n         verbose=False). Check the list of available parameters with `estimator.get_params().keys()`.\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-79-9607d39d2828>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[0mgrid_search\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpipe\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m \u001b[0mgrid_search\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_upsampled\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'description'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf_upsampled\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'ratingCategory'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\US4-S1-NLP\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    708\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    709\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 710\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    711\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    712\u001b[0m         \u001b[1;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\US4-S1-NLP\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1149\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1150\u001b[0m         \u001b[1;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1151\u001b[1;33m         \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1152\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1153\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\US4-S1-NLP\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[1;34m(candidate_params)\u001b[0m\n\u001b[0;32m    687\u001b[0m                                \u001b[1;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    688\u001b[0m                                in product(candidate_params,\n\u001b[1;32m--> 689\u001b[1;33m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[0;32m    690\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    691\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\US4-S1-NLP\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1015\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1016\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1017\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1018\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1019\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\US4-S1-NLP\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    907\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    908\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 909\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    910\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    911\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\US4-S1-NLP\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    560\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[0;32m    561\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 562\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    563\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mLokyTimeoutError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    564\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\US4-S1-NLP\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36mresult\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    430\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    431\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 432\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    433\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    434\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\US4-S1-NLP\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    382\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    383\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 384\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    385\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    386\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Invalid parameter lsi for estimator Pipeline(memory=None,\n         steps=[('vect',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=True, max_df=1.0, max_features=None,\n                                 min_df=5, ngram_range=(1, 2), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_words='english', strip_accents=None,\n                                 sublinear_tf=False,\n                                 token_patte...\n                 RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n                                        class_weight=None, criterion='gini',\n                                        max_depth=None, max_features='auto',\n                                        max_leaf_nodes=None, max_samples=None,\n                                        min_impurity_decrease=0.0,\n                                        min_impurity_split=None,\n                                        min_samples_leaf=1, min_samples_split=2,\n                                        min_weight_fraction_leaf=0.0,\n                                        n_estimators=100, n_jobs=None,\n                                        oob_score=False, random_state=None,\n                                        verbose=0, warm_start=False))],\n         verbose=False). Check the list of available parameters with `estimator.get_params().keys()`."
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "vect = TfidfVectorizer(stop_words='english', ngram_range=(1,2), min_df=5)\n",
    "rfc = RandomForestClassifier()\n",
    "svd = TruncatedSVD(n_components=100, # Just here for demo. \n",
    "                   algorithm='randomized',\n",
    "                   n_iter=10)\n",
    "\n",
    "# LSI\n",
    "lsi = Pipeline([('vect', vect), ('svd', svd)])\n",
    "\n",
    "\n",
    "# Pipe\n",
    "pipe = Pipeline([('lsi', lsi), ('clf', rfc)])\n",
    "\n",
    "\n",
    "params = { \n",
    "    'lsi__svd__n_components': [10,100,250, 400],\n",
    "    'lsi__vect__max_df':[.7, .9, .95, 1.0],\n",
    "    'clf__n_estimators':[2,5,10,20],\n",
    "    'clf__max_depth':(15,20, 25, 30)\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "# Define the Pipeline\n",
    "pipe = Pipeline([\n",
    "                 #Vectorizer\n",
    "                 ('vect', vect),\n",
    "                 # Classifier\n",
    "                 ('clf', rfc),\n",
    "                ])\n",
    "\n",
    "\n",
    "grid_search = GridSearchCV(pipe,params, cv=5, n_jobs=-1, verbose=1)\n",
    "grid_search.fit(df_upsampled['description'], df_upsampled['ratingCategory'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:   15.8s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('vect',\n",
       "                                        TfidfVectorizer(analyzer='word',\n",
       "                                                        binary=False,\n",
       "                                                        decode_error='strict',\n",
       "                                                        dtype=<class 'numpy.float64'>,\n",
       "                                                        encoding='utf-8',\n",
       "                                                        input='content',\n",
       "                                                        lowercase=True,\n",
       "                                                        max_df=1.0,\n",
       "                                                        max_features=None,\n",
       "                                                        min_df=5,\n",
       "                                                        ngram_range=(1, 2),\n",
       "                                                        norm='l2',\n",
       "                                                        preprocessor=None,\n",
       "                                                        smooth_idf=True,\n",
       "                                                        stop_words='english',\n",
       "                                                        strip...\n",
       "                                                               min_samples_leaf=1,\n",
       "                                                               min_samples_split=2,\n",
       "                                                               min_weight_fraction_leaf=0.0,\n",
       "                                                               n_estimators=100,\n",
       "                                                               n_jobs=None,\n",
       "                                                               oob_score=False,\n",
       "                                                               random_state=None,\n",
       "                                                               verbose=0,\n",
       "                                                               warm_start=False))],\n",
       "                                verbose=False),\n",
       "             iid='deprecated', n_jobs=-1,\n",
       "             param_grid={'clf__max_depth': (5, 10, 15, 20),\n",
       "                         'vect__max_df': (0.75, 1.0)},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=1)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = {\n",
    "    'vect__max_df': ( 0.75, 1.0),\n",
    "    'clf__max_depth':(5,10,15,20)\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(pipe,parameters, cv=5, n_jobs=-1, verbose=1)\n",
    "grid_search.fit(df_upsampled['description'], df_upsampled['ratingCategory'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8719201720150332"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>description</th>\n",
       "      <th>ratingCategory</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3461</td>\n",
       "      <td>\\nStyle: Speyside single malt scotch Color: Wa...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2604</td>\n",
       "      <td>\\nVery bright and lively, with a nice balance ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3341</td>\n",
       "      <td>\\nA new oloroso-forward Chivas positioned to s...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3764</td>\n",
       "      <td>\\nAged in bourbon casks and then enhanced in R...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2306</td>\n",
       "      <td>\\nThere is a freshness to the wood on the nose...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1017</th>\n",
       "      <td>2853</td>\n",
       "      <td>\\nCare for a small batch, bourbon-matured blen...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1018</th>\n",
       "      <td>219</td>\n",
       "      <td>\\nThis is the pick of the bunch, the whisky eq...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1019</th>\n",
       "      <td>1286</td>\n",
       "      <td>\\nPort Ellen, for sure! Very old-fashioned in ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1020</th>\n",
       "      <td>2201</td>\n",
       "      <td>\\nYouthful and very lively. Bold, crisp, spice...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1021</th>\n",
       "      <td>4019</td>\n",
       "      <td>\\nA mashbill of 60/20/10/10 corn/wheat/rye/mal...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1022 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                        description  ratingCategory\n",
       "0     3461  \\nStyle: Speyside single malt scotch Color: Wa...               1\n",
       "1     2604  \\nVery bright and lively, with a nice balance ...               1\n",
       "2     3341  \\nA new oloroso-forward Chivas positioned to s...               1\n",
       "3     3764  \\nAged in bourbon casks and then enhanced in R...               1\n",
       "4     2306  \\nThere is a freshness to the wood on the nose...               1\n",
       "...    ...                                                ...             ...\n",
       "1017  2853  \\nCare for a small batch, bourbon-matured blen...               1\n",
       "1018   219  \\nThis is the pick of the bunch, the whisky eq...               1\n",
       "1019  1286  \\nPort Ellen, for sure! Very old-fashioned in ...               1\n",
       "1020  2201  \\nYouthful and very lively. Bold, crisp, spice...               1\n",
       "1021  4019  \\nA mashbill of 60/20/10/10 corn/wheat/rye/mal...               1\n",
       "\n",
       "[1022 rows x 3 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8385518590998043\n"
     ]
    }
   ],
   "source": [
    "pred = grid_search.predict(test['description'])\n",
    "acc = accuracy_score(test['ratingCategory'], pred)\n",
    "\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions on test sample\n",
    "# pred = grid_search.predict(test['description'])\n",
    "submission = pd.DataFrame({'id': test['id'], 'ratingCategory':pred})\n",
    "submission['ratingCategory'] = submission['ratingCategory'].astype('int64')\n",
    "submission.to_csv(f'./data/submission{subNumber}.csv', index=False)\n",
    "subNumber += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>ratingCategory</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3461</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2604</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3341</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3764</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2306</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1017</th>\n",
       "      <td>2853</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1018</th>\n",
       "      <td>219</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1019</th>\n",
       "      <td>1286</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1020</th>\n",
       "      <td>2201</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1021</th>\n",
       "      <td>4019</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1022 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  ratingCategory\n",
       "0     3461               1\n",
       "1     2604               1\n",
       "2     3341               1\n",
       "3     3764               1\n",
       "4     2306               1\n",
       "...    ...             ...\n",
       "1017  2853               1\n",
       "1018   219               0\n",
       "1019  1286               1\n",
       "1020  2201               1\n",
       "1021  4019               0\n",
       "\n",
       "[1022 rows x 2 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.914117934915586\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_pred = grid_search.predict(train['description'])\n",
    "\n",
    "acc = accuracy_score(train['ratingCategory'], y_pred)\n",
    "\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply to your Dataset\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "from scipy.stats import randint\n",
    "\n",
    "param_dist = {\n",
    "    \n",
    "    'max_depth' : randint(3,10),\n",
    "    'min_samples_leaf': randint(2,15)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=None, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Continue Word Embedding Work Here\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "def get_word_vectors(docs):\n",
    "    return [nlp(doc).vector for doc in docs]\n",
    "\n",
    "X = get_word_vectors(train['description'])\n",
    "\n",
    "len(X) == len(train['description'])\n",
    "X_test = get_word_vectors(test['description'])\n",
    "rfc.fit(X, train['ratingCategory'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc.score(X, train['ratingCategory'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 1, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['ratingCategory'] = rfc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[['id', 'ratingCategory']].to_csv('testSolutionSubmission.csv', header=True, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make a Submission File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions on test sample\n",
    "pred = ...predict(test['description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'id': test['id'], 'ratingCategory':pred})\n",
    "submission['ratingCategory'] = submission['ratingCategory'].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make Sure the Category is an Integer\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save your Submission File\n",
    "# Best to Use an Integer or Timestamp for different versions of your model\n",
    "\n",
    "submission.to_csv(f'./data/submission{subNumber}.csv', index=False)\n",
    "subNumber += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge\n",
    "\n",
    "What you should be doing now:\n",
    "1. Join the Kaggle Competition\n",
    "2. Download the data\n",
    "3. Train a model & try: \n",
    "    - Creating a Text Extraction & Classification Pipeline\n",
    "    - Tune the pipeline with a `GridSearchCV` or `RandomizedSearchCV`\n",
    "    - Add some Latent Semantic Indexing (lsi) into your pipeline. *Note:* You can grid search a nested pipeline, but you have to use double underscores ie `lsi__svd__n_components`\n",
    "    - Try to extract word embeddings with Spacy and use those embeddings as your features for a classification model.\n",
    "4. Make a submission to Kaggle "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Post Lecture Assignment\n",
    "<a id=\"p4\"></a>\n",
    "\n",
    "Your primary assignment this afternoon is to achieve a minimum of 70% accuracy on the Kaggle competition. Once you have achieved 70% accuracy, please work on the following: \n",
    "\n",
    "1. Research \"Sentiment Analysis\". Provide answers in markdown to the following questions: \n",
    "    - What is \"Sentiment Analysis\"? \n",
    "    - Is Document Classification different than \"Sentiment Analysis\"? Provide evidence for your response\n",
    "    - How do create labeled sentiment data? Are those labels really sentiment?\n",
    "    - What are common applications of sentiment analysis?\n",
    "2. Research our why word embeddings worked better for the lecture notebook than on the whiskey competition.\n",
    "    - This [text classification documentation](https://developers.google.com/machine-learning/guides/text-classification/step-2-5) from Google might be of interest\n",
    "    - Neural Networks are becoming more popular for document classification. Why is that the case?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "U4-S1-NLP (Python3)",
   "language": "python",
   "name": "u4-s1-nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
