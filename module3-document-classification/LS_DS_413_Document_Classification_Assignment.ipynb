{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lambda School Data Science\n",
    "\n",
    "*Unit 4, Sprint 1, Module 3*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Document Classification (Assignment)\n",
    "\n",
    "This notebook is for you to practice skills during lecture.\n",
    "\n",
    "Today's guided module project and assignment will be different. You already know how to do classification. You ready know how to extract features from documents. So? That means you're ready to combine and practice those skills in a kaggle competition. We we will open with a five minute sprint explaining the competition, and then give you 25 minutes to work. After those twenty five minutes are up, I will give a 5-minute demo an NLP technique that will help you with document classification (*and **maybe** the competition*).\n",
    "\n",
    "Today's all about having fun and practicing your skills.\n",
    "\n",
    "## Sections\n",
    "* <a href=\"#p1\">Part 1</a>: Text Feature Extraction & Classification Pipelines\n",
    "* <a href=\"#p2\">Part 2</a>: Latent Semantic Indexing\n",
    "* <a href=\"#p3\">Part 3</a>: Word Embeddings with Spacy\n",
    "* <a href=\"#p4\">Part 4</a>: Post Lecture Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Feature Extraction & Classification Pipelines (Learn)\n",
    "<a id=\"p1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "## Follow Along \n",
    "\n",
    "What you should be doing now:\n",
    "1. Join the Kaggle Competition\n",
    "2. Download the data\n",
    "3. Train a model (try using the pipe method I just demoed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Competition Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Statements\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# You may need to change the path\n",
    "train = pd.read_csv('./data/train.csv')\n",
    "test = pd.read_csv('./data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = train['clean_descriptions']\n",
    "target = train['ratingCategory']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['clean_descriptions'] = train['description'].apply(lambda x: x[1:-1].replace(',', ' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>description</th>\n",
       "      <th>ratingCategory</th>\n",
       "      <th>clean_descriptions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1321</td>\n",
       "      <td>\\nSometimes, when whisky is batched, a few lef...</td>\n",
       "      <td>1</td>\n",
       "      <td>Sometimes  when whisky is batched  a few lefto...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3861</td>\n",
       "      <td>\\nAn uncommon exclusive bottling of a 6 year o...</td>\n",
       "      <td>0</td>\n",
       "      <td>An uncommon exclusive bottling of a 6 year old...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>655</td>\n",
       "      <td>\\nThis release is a port version of Amrut’s In...</td>\n",
       "      <td>1</td>\n",
       "      <td>This release is a port version of Amrut’s Inte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>555</td>\n",
       "      <td>\\nThis 41 year old single cask was aged in a s...</td>\n",
       "      <td>1</td>\n",
       "      <td>This 41 year old single cask was aged in a she...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1965</td>\n",
       "      <td>\\nQuite herbal on the nose, with aromas of dri...</td>\n",
       "      <td>1</td>\n",
       "      <td>Quite herbal on the nose  with aromas of dried...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id                                        description  ratingCategory  \\\n",
       "0  1321  \\nSometimes, when whisky is batched, a few lef...               1   \n",
       "1  3861  \\nAn uncommon exclusive bottling of a 6 year o...               0   \n",
       "2   655  \\nThis release is a port version of Amrut’s In...               1   \n",
       "3   555  \\nThis 41 year old single cask was aged in a s...               1   \n",
       "4  1965  \\nQuite herbal on the nose, with aromas of dri...               1   \n",
       "\n",
       "                                  clean_descriptions  \n",
       "0  Sometimes  when whisky is batched  a few lefto...  \n",
       "1  An uncommon exclusive bottling of a 6 year old...  \n",
       "2  This release is a port version of Amrut’s Inte...  \n",
       "3  This 41 year old single cask was aged in a she...  \n",
       "4  Quite herbal on the nose  with aromas of dried...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       Sometimes, when whisky is batched, a few lefto...\n",
       "1       An uncommon exclusive bottling of a 6 year old...\n",
       "2       This release is a port version of Amrut’s Inte...\n",
       "3       This 41 year old single cask was aged in a she...\n",
       "4       Quite herbal on the nose, with aromas of dried...\n",
       "                              ...                        \n",
       "4082    What lies beneath the surface of Dewar’s? Here...\n",
       "4083    After 6 to 7 years of maturation in bourbon ca...\n",
       "4084    Bright, delicate, and approachable. While not ...\n",
       "4085    I’m calling this the pitmaster’s dram: the nos...\n",
       "4086    Spicy sultanas, greengage plums, toffee, and n...\n",
       "Name: clean_descriptions, Length: 4087, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Pipeline Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = TfidfVectorizer(stop_words='english', ngram_range=(1,2), min_df=5)\n",
    "rfc = RandomForestClassifier()\n",
    "\n",
    "\n",
    "# Define the Pipeline\n",
    "pipe = Pipeline([\n",
    "                 #Vectorizer\n",
    "                 ('vect', vect),\n",
    "                 # Classifier\n",
    "                 ('clf', rfc),\n",
    "                ])\n",
    "\n",
    "# The pipeline puts together a bunch fit then transform,fit then predict. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Your Search Space\n",
    "You're looking for both the best hyperparameters of your vectorizer and your classification model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   14.6s\n",
      "[Parallel(n_jobs=-1)]: Done 160 out of 160 | elapsed:   48.7s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('vect',\n",
       "                                        TfidfVectorizer(analyzer='word',\n",
       "                                                        binary=False,\n",
       "                                                        decode_error='strict',\n",
       "                                                        dtype=<class 'numpy.float64'>,\n",
       "                                                        encoding='utf-8',\n",
       "                                                        input='content',\n",
       "                                                        lowercase=True,\n",
       "                                                        max_df=1.0,\n",
       "                                                        max_features=None,\n",
       "                                                        min_df=5,\n",
       "                                                        ngram_range=(1, 2),\n",
       "                                                        norm='l2',\n",
       "                                                        preprocessor=None,\n",
       "                                                        smooth_idf=True,\n",
       "                                                        stop_words='english',\n",
       "                                                        strip...\n",
       "                                                               n_jobs=None,\n",
       "                                                               oob_score=False,\n",
       "                                                               random_state=None,\n",
       "                                                               verbose=0,\n",
       "                                                               warm_start=False))],\n",
       "                                verbose=False),\n",
       "             iid='deprecated', n_jobs=-1,\n",
       "             param_grid={'clf__max_depth': (15, 20),\n",
       "                         'clf__n_estimators': (5, 10),\n",
       "                         'vect__max_df': (0.75, 1.0),\n",
       "                         'vect__max_features': (500, 1000),\n",
       "                         'vect__min_df': (0.02, 0.05)},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "parameters = {\n",
    "    'vect__max_df': ( 0.75, 1.0),\n",
    "    'vect__min_df': (.02, .05),\n",
    "    'vect__max_features': (500,1000),\n",
    "    'clf__n_estimators':(5, 10,),\n",
    "    'clf__max_depth':(15,20)\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(pipe,parameters, cv=5, n_jobs=-1, verbose=1)\n",
    "grid_search.fit(data, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7186205121605971"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1], dtype=int64)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.predict(['Send me lots of money now', 'you won the lottery in Nigeria'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make a Submission File\n",
    "*Note:* In a typical Kaggle competition, you are only allowed two submissions a day, so you only submit if you feel you cannot achieve higher test accuracy. For this competition the max daily submissions are capped at **20**. Submit for each demo and for your assignment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions on test sample\n",
    "pred = grid_search.predict(test['description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'id': test['id'], 'ratingCategory':pred})\n",
    "submission['ratingCategory'] = submission['ratingCategory'].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>ratingCategory</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3461</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2604</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3341</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3764</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2306</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id  ratingCategory\n",
       "0  3461               1\n",
       "1  2604               1\n",
       "2  3341               1\n",
       "3  3764               1\n",
       "4  2306               1"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make Sure the Category is an Integer\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "subNumber = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save your Submission File\n",
    "# Best to Use an Integer or Timestamp for different versions of your model\n",
    "\n",
    "submission.to_csv(f'./data/submission{subNumber}.csv', index=False)\n",
    "subNumber += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge\n",
    "\n",
    "You're trying to achieve a minimum of 70% Accuracy on your model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Latent Semantic Indexing (Learn)\n",
    "<a id=\"p2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "## Follow Along\n",
    "1. Join the Kaggle Competition\n",
    "2. Download the data\n",
    "3. Train a model & try: \n",
    "    - Creating a Text Extraction & Classification Pipeline\n",
    "    - Tune the pipeline with a `GridSearchCV` or `RandomizedSearchCV`\n",
    "    - Add some Latent Semantic Indexing (lsi) into your pipeline. *Note:* You can grid search a nested pipeline, but you have to use double underscores ie `lsi__svd__n_components`\n",
    "4. Make a submission to Kaggle \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Pipeline Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "svd = TruncatedSVD(n_components=100, # Just here for demo. \n",
    "                   algorithm='randomized',\n",
    "                   n_iter=10)\n",
    "\n",
    "params = { \n",
    "    'lsi__svd__n_components': [10,100,250, 400],\n",
    "    'lsi__vect__max_df':[.7, .9, .95, 1.0],\n",
    "    'clf__n_estimators':[2,5,10,20],\n",
    "    'clf__max_depth':(15,20, 25, 30)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSI\n",
    "lsi = Pipeline([('vect', vect), ('svd', svd)])\n",
    "\n",
    "\n",
    "# Pipe\n",
    "pipe = Pipeline([('lsi', lsi), ('clf', rfc)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(memory=None,\n",
      "         steps=[('vect',\n",
      "                 TfidfVectorizer(analyzer='word', binary=False,\n",
      "                                 decode_error='strict',\n",
      "                                 dtype=<class 'numpy.float64'>,\n",
      "                                 encoding='utf-8', input='content',\n",
      "                                 lowercase=True, max_df=1.0, max_features=None,\n",
      "                                 min_df=5, ngram_range=(1, 2), norm='l2',\n",
      "                                 preprocessor=None, smooth_idf=True,\n",
      "                                 stop_words='english', strip_accents=None,\n",
      "                                 sublinear_tf=False,\n",
      "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "                                 tokenizer=None, use_idf=True,\n",
      "                                 vocabulary=None)),\n",
      "                ('svd',\n",
      "                 TruncatedSVD(algorithm='randomized', n_components=100,\n",
      "                              n_iter=10, random_state=None, tol=0.0))],\n",
      "         verbose=False)\n"
     ]
    }
   ],
   "source": [
    "print(lsi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(memory=None,\n",
      "         steps=[('lsi',\n",
      "                 Pipeline(memory=None,\n",
      "                          steps=[('vect',\n",
      "                                  TfidfVectorizer(analyzer='word', binary=False,\n",
      "                                                  decode_error='strict',\n",
      "                                                  dtype=<class 'numpy.float64'>,\n",
      "                                                  encoding='utf-8',\n",
      "                                                  input='content',\n",
      "                                                  lowercase=True, max_df=1.0,\n",
      "                                                  max_features=None, min_df=5,\n",
      "                                                  ngram_range=(1, 2), norm='l2',\n",
      "                                                  preprocessor=None,\n",
      "                                                  smooth_idf=True,\n",
      "                                                  stop_words='english',\n",
      "                                                  strip_accents=...\n",
      "                 RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
      "                                        class_weight=None, criterion='gini',\n",
      "                                        max_depth=None, max_features='auto',\n",
      "                                        max_leaf_nodes=None, max_samples=None,\n",
      "                                        min_impurity_decrease=0.0,\n",
      "                                        min_impurity_split=None,\n",
      "                                        min_samples_leaf=1, min_samples_split=2,\n",
      "                                        min_weight_fraction_leaf=0.0,\n",
      "                                        n_estimators=100, n_jobs=None,\n",
      "                                        oob_score=False, random_state=None,\n",
      "                                        verbose=0, warm_start=False))],\n",
      "         verbose=False)\n"
     ]
    }
   ],
   "source": [
    "print(pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 256 candidates, totalling 1280 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   25.0s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:  6.8min\n",
      "[Parallel(n_jobs=-1)]: Done 792 tasks      | elapsed: 13.0min\n",
      "[Parallel(n_jobs=-1)]: Done 1242 tasks      | elapsed: 20.5min\n",
      "[Parallel(n_jobs=-1)]: Done 1280 out of 1280 | elapsed: 21.6min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('lsi',\n",
       "                                        Pipeline(memory=None,\n",
       "                                                 steps=[('vect',\n",
       "                                                         TfidfVectorizer(analyzer='word',\n",
       "                                                                         binary=False,\n",
       "                                                                         decode_error='strict',\n",
       "                                                                         dtype=<class 'numpy.float64'>,\n",
       "                                                                         encoding='utf-8',\n",
       "                                                                         input='content',\n",
       "                                                                         lowercase=True,\n",
       "                                                                         max_df=1.0,\n",
       "                                                                         max_features=None,\n",
       "                                                                         min_df=5,\n",
       "                                                                         ngram_range=(1,\n",
       "                                                                                      2),\n",
       "                                                                         norm='l2',\n",
       "                                                                         preprocessor=None,\n",
       "                                                                         smooth_...\n",
       "                                                               n_jobs=None,\n",
       "                                                               oob_score=False,\n",
       "                                                               random_state=None,\n",
       "                                                               verbose=0,\n",
       "                                                               warm_start=False))],\n",
       "                                verbose=False),\n",
       "             iid='deprecated', n_jobs=-1,\n",
       "             param_grid={'clf__max_depth': (15, 20, 25, 30),\n",
       "                         'clf__n_estimators': [2, 5, 10, 20],\n",
       "                         'lsi__svd__n_components': [10, 100, 250, 400],\n",
       "                         'lsi__vect__max_df': [0.7, 0.9, 0.95, 1.0]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=1)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit\n",
    "grid_search = GridSearchCV(pipe,params, cv=5, n_jobs=-1, verbose=1)\n",
    "grid_search.fit(data,target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7262092514506827"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Your Search Space\n",
    "You're looking for both the best hyperparameters of your vectorizer and your classification model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make a Submission File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions on test sample\n",
    "pred = grid_search.predict(test['description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'id': test['id'], 'ratingCategory':pred})\n",
    "submission['ratingCategory'] = submission['ratingCategory'].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>ratingCategory</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3461</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2604</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3341</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3764</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2306</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id  ratingCategory\n",
       "0  3461               1\n",
       "1  2604               1\n",
       "2  3341               1\n",
       "3  3764               1\n",
       "4  2306               1"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make Sure the Category is an Integer\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save your Submission File\n",
    "# Best to Use an Integer or Timestamp for different versions of your model\n",
    "\n",
    "submission.to_csv(f'./data/submission{subNumber}.csv', index=False)\n",
    "subNumber += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge\n",
    "\n",
    "Continue to apply Latent Semantic Indexing (LSI) to various datasets. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Embeddings with Spacy (Learn)\n",
    "<a id=\"p3\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Follow Along"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = []\n",
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "from spacy.tokenizer import Tokenizer\n",
    "tokenizer = Tokenizer(nlp.vocab)\n",
    "\"\"\" Update those tokens w/o stopwords\"\"\"\n",
    "for doc in tokenizer.pipe(train['clean_descriptions'], batch_size=500):\n",
    "    \n",
    "    doc_tokens = []\n",
    "    \n",
    "    for token in doc:\n",
    "        if (token.is_stop == False) & (token.is_punct == False):\n",
    "            doc_tokens.append(token.text.lower())\n",
    "\n",
    "    tokens.append(doc_tokens)\n",
    "\n",
    "train['tokens'] = tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['token_str'] = [','.join(map(str, l)) for l in train['tokens']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['token_str'] = train['token_str'].apply(lambda x: x[:-1].replace(',', ' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kyleyates/anaconda3/envs/U4-S1-NLP/lib/python3.7/site-packages/ipykernel_launcher.py:1: FutureWarning: Passing a negative integer is deprecated in version 1.0 and will not be supported in future version. Instead, use None to not limit the column width.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['token_str'] = train['tokens']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['token_str'] = train['token_str'].apply(tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cooley',\n",
       " 'produced',\n",
       " 'great',\n",
       " 'irish',\n",
       " 'single',\n",
       " 'malt',\n",
       " 'whiskeys',\n",
       " 'slouch',\n",
       " 'pulls',\n",
       " 'trick',\n",
       " 'irish',\n",
       " 'sweet',\n",
       " 'lush',\n",
       " 'pear',\n",
       " 'fermenting',\n",
       " 'apple',\n",
       " 'yellow',\n",
       " 'fruit',\n",
       " 'notes',\n",
       " 'distinctively',\n",
       " 'single',\n",
       " 'malt',\n",
       " 'mainly',\n",
       " 'barley',\n",
       " 'held',\n",
       " 'check',\n",
       " 'influence',\n",
       " 'tannin',\n",
       " 'spice',\n",
       " 'bit',\n",
       " 'like',\n",
       " 'fruit',\n",
       " 'cordial',\n",
       " 'oak',\n",
       " 'doesnt',\n",
       " 'overstay',\n",
       " 'welcome',\n",
       " 'nice',\n",
       " 'pepper',\n",
       " 'flourish',\n",
       " 'finis']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['token_str'][5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=None, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Continue Word Embedding Work Here\n",
    "import spacy\n",
    "\n",
    "rfc = RandomForestClassifier()\n",
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "\n",
    "def get_word_vectors(docs):\n",
    "    return [nlp(doc).vector for doc in docs]\n",
    "\n",
    "X = get_word_vectors(train['token_str'])\n",
    "\n",
    "len(X) == len(train['token_str'])\n",
    "X_test = get_word_vectors(test['description'])\n",
    "rfc.fit(X, train['ratingCategory'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9997553217518963"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc.score(X, train['ratingCategory'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, ..., 0, 1, 0])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['ratingCategory'] = rfc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[['id', 'ratingCategory']].to_csv('testSolutionSubmission3.csv', header=True, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge\n",
    "\n",
    "What you should be doing now:\n",
    "1. Join the Kaggle Competition\n",
    "2. Download the data\n",
    "3. Train a model & try: \n",
    "    - Creating a Text Extraction & Classification Pipeline\n",
    "    - Tune the pipeline with a `GridSearchCV` or `RandomizedSearchCV`\n",
    "    - Add some Latent Semantic Indexing (lsi) into your pipeline. *Note:* You can grid search a nested pipeline, but you have to use double underscores ie `lsi__svd__n_components`\n",
    "    - Try to extract word embeddings with Spacy and use those embeddings as your features for a classification model.\n",
    "4. Make a submission to Kaggle "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Post Lecture Assignment\n",
    "<a id=\"p4\"></a>\n",
    "\n",
    "Your primary assignment this afternoon is to achieve a minimum of 70% accuracy on the Kaggle competition. Once you have achieved 70% accuracy, please work on the following: \n",
    "\n",
    "1. Research \"Sentiment Analysis\". Provide answers in markdown to the following questions: \n",
    "    - What is \"Sentiment Analysis\"? \n",
    "    - Is Document Classification different than \"Sentiment Analysis\"? Provide evidence for your response\n",
    "    - How do create labeled sentiment data? Are those labels really sentiment?\n",
    "    - What are common applications of sentiment analysis?\n",
    "2. Research our why word embeddings worked better for the lecture notebook than on the whiskey competition.\n",
    "    - This [text classification documentation](https://developers.google.com/machine-learning/guides/text-classification/step-2-5) from Google might be of interest\n",
    "    - Neural Networks are becoming more popular for document classification. Why is that the case?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def tokenize(text):\n",
    "    tokens = text.lower().split()\n",
    "#     print(tokens)\n",
    "#     tokens = re.sub('[^a-zA-Z 0-9]', '', text)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['clean_description2'] = train['clean_descriptions'].apply(tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['this',\n",
       " 'release',\n",
       " 'is',\n",
       " 'a',\n",
       " 'port',\n",
       " 'version',\n",
       " 'of',\n",
       " 'amruts',\n",
       " 'intermediate',\n",
       " 'sherry',\n",
       " 'a',\n",
       " 'sort',\n",
       " 'of',\n",
       " 'port',\n",
       " 'pipe',\n",
       " 'sandwich',\n",
       " 'the',\n",
       " 'spirit',\n",
       " 'is',\n",
       " 'matured',\n",
       " 'in',\n",
       " 'both',\n",
       " 'unused',\n",
       " 'casks',\n",
       " 'and',\n",
       " 'bourbon',\n",
       " 'casks',\n",
       " 'then',\n",
       " 'spends',\n",
       " 'a',\n",
       " 'few',\n",
       " 'months',\n",
       " 'in',\n",
       " 'port',\n",
       " 'pipes',\n",
       " 'and',\n",
       " 'then',\n",
       " 'returns',\n",
       " 'to',\n",
       " 'bourbon',\n",
       " 'casks',\n",
       " 'the',\n",
       " 'result',\n",
       " 'is',\n",
       " 'a',\n",
       " 'pink',\n",
       " 'floyd',\n",
       " 'show',\n",
       " 'of',\n",
       " 'a',\n",
       " 'whisky',\n",
       " 'vibrant',\n",
       " 'colorful',\n",
       " 'complex',\n",
       " 'and',\n",
       " 'nearly',\n",
       " 'too',\n",
       " 'much',\n",
       " 'a',\n",
       " 'blackcurrant',\n",
       " 'and',\n",
       " 'wispy',\n",
       " 'smoky',\n",
       " 'nose',\n",
       " 'gives',\n",
       " 'way',\n",
       " 'to',\n",
       " 'an',\n",
       " 'intense',\n",
       " 'and',\n",
       " 'bittersweet',\n",
       " 'mix',\n",
       " 'of',\n",
       " 'chili',\n",
       " 'blackcurrant',\n",
       " 'oak',\n",
       " 'damson',\n",
       " 'dark',\n",
       " 'chocolate',\n",
       " 'and',\n",
       " 'peat',\n",
       " 'astounding']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['clean_description2'][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('finish', 2285),\n",
       " ('oak', 2060),\n",
       " ('palate', 1897),\n",
       " ('nose', 1860),\n",
       " ('sweet', 1731),\n",
       " ('notes', 1720),\n",
       " ('vanilla', 1711),\n",
       " ('fruit', 1412),\n",
       " ('whisky', 1377),\n",
       " ('chocolate', 1186),\n",
       " ('spice', 1089),\n",
       " ('old', 964),\n",
       " ('orange', 916),\n",
       " ('malt', 896),\n",
       " ('smoke', 874),\n",
       " ('cinnamon', 873),\n",
       " ('spices', 867),\n",
       " ('caramel', 845),\n",
       " ('pepper', 843),\n",
       " ('sherry', 804)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Object from Base Python\n",
    "from collections import Counter\n",
    "\n",
    "# The object `Counter` takes an iterable, but you can instaniate an empty one and update it. \n",
    "word_counts = Counter()\n",
    "\n",
    "# Update it based on a split of each of our documents\n",
    "train['token_str'].apply(lambda x: word_counts.update(x))\n",
    "\n",
    "# Print out the 10 most common words\n",
    "word_counts.most_common(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Apply to your Dataset\n",
    "\n",
    "# from sklearn.model_selection import RandomizedSearchCV\n",
    "# from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# from scipy.stats import randint\n",
    "\n",
    "# param_dist = {\n",
    "    \n",
    "#     'max_depth' : randint(3,10),\n",
    "#     'min_samples_leaf': randint(2,15)\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "sns.countplot(train['ratingCategory']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UPSAMPLING EXAMPLE:\n",
    "\n",
    "\n",
    "# import pandas as pd\n",
    "# from sklearn.utils import resample\n",
    "# # You may need to change the path\n",
    "# train = pd.read_csv('./data/train.csv')\n",
    "# test = pd.read_csv('./data/test.csv')\n",
    "# minority = train[train['ratingCategory'] == 0]\n",
    "# majority = train[train['ratingCategory'] == 1]\n",
    "# df_minority_upsampled = resample(minority,\n",
    "#                                  replace=True,\n",
    "#                                  n_samples=majority.shape[0]\n",
    "#                                 )\n",
    "# df_upsampled = pd.concat([majority, df_minority_upsampled])\n",
    "\n",
    "\n",
    "\n",
    "# # DOWNSAMPLING EXAMPLE:\n",
    "\n",
    "# import pandas as pd\n",
    "# from sklearn.utils import resample\n",
    "# # You may need to change the path\n",
    "# train = pd.read_csv('./data/train.csv')\n",
    "# test = pd.read_csv('./data/test.csv')\n",
    "# minority = train[train['ratingCategory'] == 0]\n",
    "# majority = train[train['ratingCategory'] == 1]\n",
    "# df_majority_downsampled = resample(majority,\n",
    "#                                  replace=False,\n",
    "#                                  n_samples=minority.shape[0]\n",
    "#                                 )\n",
    "# df_downsampled = pd.concat([minority, df_majority_downsampled])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.utils import resample\n",
    "# You may need to change the path\n",
    "\n",
    "minority = train[train['ratingCategory'] == 0]\n",
    "majority = train[train['ratingCategory'] == 1]\n",
    "df_minority_upsampled = resample(minority,\n",
    "                                 replace=True,\n",
    "                                 n_samples=majority.shape[0]\n",
    "                                )\n",
    "df_upsampled = pd.concat([majority, df_minority_upsampled])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>description</th>\n",
       "      <th>ratingCategory</th>\n",
       "      <th>clean_descriptions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1321</td>\n",
       "      <td>\\nSometimes, when whisky is batched, a few lef...</td>\n",
       "      <td>1</td>\n",
       "      <td>Sometimes, when whisky is batched, a few lefto...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>655</td>\n",
       "      <td>\\nThis release is a port version of Amrut’s In...</td>\n",
       "      <td>1</td>\n",
       "      <td>This release is a port version of Amrut’s Inte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>555</td>\n",
       "      <td>\\nThis 41 year old single cask was aged in a s...</td>\n",
       "      <td>1</td>\n",
       "      <td>This 41 year old single cask was aged in a she...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1965</td>\n",
       "      <td>\\nQuite herbal on the nose, with aromas of dri...</td>\n",
       "      <td>1</td>\n",
       "      <td>Quite herbal on the nose, with aromas of dried...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3190</td>\n",
       "      <td>\\nCooley produced some great Irish single malt...</td>\n",
       "      <td>1</td>\n",
       "      <td>Cooley produced some great Irish single malt w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2948</th>\n",
       "      <td>4815</td>\n",
       "      <td>\\nComus is the name of a frankly terrifying En...</td>\n",
       "      <td>0</td>\n",
       "      <td>Comus is the name of a frankly terrifying Engl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4817</td>\n",
       "      <td>\\nMacQueen’s has an impressive range of age st...</td>\n",
       "      <td>0</td>\n",
       "      <td>MacQueen’s has an impressive range of age stat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1217</th>\n",
       "      <td>4344</td>\n",
       "      <td>\\nMatured in a combination of first-fill Spani...</td>\n",
       "      <td>0</td>\n",
       "      <td>Matured in a combination of first-fill Spanish...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3639</th>\n",
       "      <td>4758</td>\n",
       "      <td>\\nInteresting: “Bottled by The Tennessee Spiri...</td>\n",
       "      <td>0</td>\n",
       "      <td>Interesting: “Bottled by The Tennessee Spirits...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3687</th>\n",
       "      <td>3922</td>\n",
       "      <td>\\nAs young a Caledonian as you’ll find; I foun...</td>\n",
       "      <td>0</td>\n",
       "      <td>As young a Caledonian as you’ll find; I found ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5762 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                        description  ratingCategory  \\\n",
       "0     1321  \\nSometimes, when whisky is batched, a few lef...               1   \n",
       "2      655  \\nThis release is a port version of Amrut’s In...               1   \n",
       "3      555  \\nThis 41 year old single cask was aged in a s...               1   \n",
       "4     1965  \\nQuite herbal on the nose, with aromas of dri...               1   \n",
       "5     3190  \\nCooley produced some great Irish single malt...               1   \n",
       "...    ...                                                ...             ...   \n",
       "2948  4815  \\nComus is the name of a frankly terrifying En...               0   \n",
       "8     4817  \\nMacQueen’s has an impressive range of age st...               0   \n",
       "1217  4344  \\nMatured in a combination of first-fill Spani...               0   \n",
       "3639  4758  \\nInteresting: “Bottled by The Tennessee Spiri...               0   \n",
       "3687  3922  \\nAs young a Caledonian as you’ll find; I foun...               0   \n",
       "\n",
       "                                     clean_descriptions  \n",
       "0     Sometimes, when whisky is batched, a few lefto...  \n",
       "2     This release is a port version of Amrut’s Inte...  \n",
       "3     This 41 year old single cask was aged in a she...  \n",
       "4     Quite herbal on the nose, with aromas of dried...  \n",
       "5     Cooley produced some great Irish single malt w...  \n",
       "...                                                 ...  \n",
       "2948  Comus is the name of a frankly terrifying Engl...  \n",
       "8     MacQueen’s has an impressive range of age stat...  \n",
       "1217  Matured in a combination of first-fill Spanish...  \n",
       "3639  Interesting: “Bottled by The Tennessee Spirits...  \n",
       "3687  As young a Caledonian as you’ll find; I found ...  \n",
       "\n",
       "[5762 rows x 4 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_upsampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "sns.countplot(train['ratingCategory']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed:  2.2min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('lsi',\n",
       "                                        Pipeline(memory=None,\n",
       "                                                 steps=[('vect',\n",
       "                                                         TfidfVectorizer(analyzer='word',\n",
       "                                                                         binary=False,\n",
       "                                                                         decode_error='strict',\n",
       "                                                                         dtype=<class 'numpy.float64'>,\n",
       "                                                                         encoding='utf-8',\n",
       "                                                                         input='content',\n",
       "                                                                         lowercase=True,\n",
       "                                                                         max_df=1.0,\n",
       "                                                                         max_features=None,\n",
       "                                                                         min_df=5,\n",
       "                                                                         ngram_range=(1,\n",
       "                                                                                      2),\n",
       "                                                                         norm='l2',\n",
       "                                                                         preprocessor=None,\n",
       "                                                                         smooth_...\n",
       "                                                               min_samples_leaf=2,\n",
       "                                                               min_samples_split=2,\n",
       "                                                               min_weight_fraction_leaf=0.0,\n",
       "                                                               n_estimators=100,\n",
       "                                                               n_jobs=None,\n",
       "                                                               oob_score=False,\n",
       "                                                               random_state=None,\n",
       "                                                               verbose=0,\n",
       "                                                               warm_start=False))],\n",
       "                                verbose=False),\n",
       "             iid='deprecated', n_jobs=-1,\n",
       "             param_grid={'clf__max_depth': (15, 20, 30),\n",
       "                         'lsi__svd__n_components': [10, 200, 400]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=1)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "vect = TfidfVectorizer(stop_words='english', ngram_range=(1,2), min_df=5)\n",
    "rfc = RandomForestClassifier(class_weight=\"balanced\", min_samples_leaf=2)\n",
    "svd = TruncatedSVD(n_components=75,  \n",
    "                   algorithm='randomized',\n",
    "                   n_iter=10)\n",
    "\n",
    "# LSI\n",
    "lsi = Pipeline([('vect', vect), ('svd', svd)])\n",
    "\n",
    "\n",
    "# Pipe\n",
    "pipe = Pipeline([('lsi', lsi), ('clf', rfc)])\n",
    "\n",
    "\n",
    "params = { \n",
    "    'lsi__svd__n_components': [10, 200, 400],\n",
    "    'clf__max_depth':(0,20,30)\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "grid_search = GridSearchCV(pipe,params, cv=5, n_jobs=-1, verbose=1)\n",
    "grid_search.fit(train['clean_descriptions'], train['ratingCategory'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clear\n"
     ]
    }
   ],
   "source": [
    "# parameters = {\n",
    "#     'vect__max_df': ( 0.75, 1.0),\n",
    "#     'clf__max_depth':(5,10,15,20)\n",
    "# }\n",
    "\n",
    "# grid_search = GridSearchCV(pipe,parameters, cv=5, n_jobs=-1, verbose=1)\n",
    "# grid_search.fit(df_upsampled['description'], df_upsampled['ratingCategory'])\n",
    "print ('clear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9166948238893706"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3461</td>\n",
       "      <td>\\nStyle: Speyside single malt scotch Color: Wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2604</td>\n",
       "      <td>\\nVery bright and lively, with a nice balance ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3341</td>\n",
       "      <td>\\nA new oloroso-forward Chivas positioned to s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3764</td>\n",
       "      <td>\\nAged in bourbon casks and then enhanced in R...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2306</td>\n",
       "      <td>\\nThere is a freshness to the wood on the nose...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1017</th>\n",
       "      <td>2853</td>\n",
       "      <td>\\nCare for a small batch, bourbon-matured blen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1018</th>\n",
       "      <td>219</td>\n",
       "      <td>\\nThis is the pick of the bunch, the whisky eq...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1019</th>\n",
       "      <td>1286</td>\n",
       "      <td>\\nPort Ellen, for sure! Very old-fashioned in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1020</th>\n",
       "      <td>2201</td>\n",
       "      <td>\\nYouthful and very lively. Bold, crisp, spice...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1021</th>\n",
       "      <td>4019</td>\n",
       "      <td>\\nA mashbill of 60/20/10/10 corn/wheat/rye/mal...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1022 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                        description\n",
       "0     3461  \\nStyle: Speyside single malt scotch Color: Wa...\n",
       "1     2604  \\nVery bright and lively, with a nice balance ...\n",
       "2     3341  \\nA new oloroso-forward Chivas positioned to s...\n",
       "3     3764  \\nAged in bourbon casks and then enhanced in R...\n",
       "4     2306  \\nThere is a freshness to the wood on the nose...\n",
       "...    ...                                                ...\n",
       "1017  2853  \\nCare for a small batch, bourbon-matured blen...\n",
       "1018   219  \\nThis is the pick of the bunch, the whisky eq...\n",
       "1019  1286  \\nPort Ellen, for sure! Very old-fashioned in ...\n",
       "1020  2201  \\nYouthful and very lively. Bold, crisp, spice...\n",
       "1021  4019  \\nA mashbill of 60/20/10/10 corn/wheat/rye/mal...\n",
       "\n",
       "[1022 rows x 2 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9986115931968067\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "pred = grid_search.predict(df_upsampled['description'])\n",
    "acc = accuracy_score(df_upsampled['ratingCategory'], pred)\n",
    "\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9640322975287497\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_pred = grid_search.predict(train['description'])\n",
    "\n",
    "acc = accuracy_score(train['ratingCategory'], y_pred)\n",
    "\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "subNumber = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>ratingCategory</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3461</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2604</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3341</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3764</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2306</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1017</th>\n",
       "      <td>2853</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1018</th>\n",
       "      <td>219</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1019</th>\n",
       "      <td>1286</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1020</th>\n",
       "      <td>2201</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1021</th>\n",
       "      <td>4019</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1022 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  ratingCategory\n",
       "0     3461               1\n",
       "1     2604               1\n",
       "2     3341               1\n",
       "3     3764               1\n",
       "4     2306               1\n",
       "...    ...             ...\n",
       "1017  2853               1\n",
       "1018   219               1\n",
       "1019  1286               1\n",
       "1020  2201               1\n",
       "1021  4019               1\n",
       "\n",
       "[1022 rows x 2 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions on test sample\n",
    "pred = grid_search.predict(test['description'])\n",
    "submission = pd.DataFrame({'id': test['id'], 'ratingCategory':pred})\n",
    "submission['ratingCategory'] = submission['ratingCategory'].astype('int64')\n",
    "submission.to_csv(f'./data/submission{subNumber}.csv', index=False)\n",
    "subNumber += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is \"Sentiment Analysis\"?\n",
    "\n",
    "A: A method for \"analyzing sentiment\" within various forms of text.\n",
    "\n",
    "\n",
    "Is Document Classification different than \"Sentiment Analysis\"? Provide evidence for your response:\n",
    "\n",
    "A: "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "U4-S1-NLP (Python3)",
   "language": "python",
   "name": "u4-s1-nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
